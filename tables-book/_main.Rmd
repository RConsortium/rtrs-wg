--- 
title: "Tables in Clinical Trials with R"
author: "R Consortium Tables Working Group"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
documentclass: book
bibliography:
- book.bib
- packages.bib
description: |
  Example code to create tables commonly used for analyzing clinical trials data.
link-citations: yes
github-repo: "RConsortium/rtrs-wg"
editor_options:
  chunk_output_type: console
---
```{r include=FALSE, cache=FALSE}
library(knitr)
library(magrittr)
library(ragg)
library(random.cdisc.data)

is_doconvable <- require("doconv") && locatexec::exec_available("word")
is_webshotable <- require("webshot2")

is_truthy <- function(x) {
  if (inherits(x, "try-error"))
    return(FALSE)
  if (!is.atomic(x))
    return(TRUE)
  if (is.null(x))
    return(FALSE)
  if (length(x) == 0)
    return(FALSE)
  if (all(is.na(x)))
    return(FALSE)
  if (is.character(x) && !any(nzchar(stats::na.omit(x))))
    return(FALSE)
  if (is.logical(x) && !any(stats::na.omit(x)))
    return(FALSE)
  return(TRUE)
}

process_link_preview_options  <- function(options){
  if(!is_truthy(options$link_preview)) return("")
  if(!options$link_preview) return("")
  if(!is_truthy(options$path_to_doc)) return("")

  png_file <- gsub("\\.(pptx|docx|pdf|html)$", ".png", options$path_to_doc)
  width <- options$width
  if(is.null(width)) {
    if(!grepl("\\.pptx$", options$path_to_doc)) width <- 650
    else width <- 750
  }

  if(!file.exists(png_file) && is_doconvable && grepl("\\.docx$", options$path_to_doc)) {
    doconv::to_miniature(filename = options$path_to_doc, fileout = png_file, width = width, row = options$row)
  } else if(!file.exists(png_file) && is_doconvable && grepl("\\.pdf$", options$path_to_doc)) {
    doconv::to_miniature(filename = options$path_to_doc, fileout = png_file, width = width, row = options$row)
  } else if(!file.exists(png_file) && is_doconvable && grepl("\\.pptx$", options$path_to_doc)) {
    doconv::to_miniature(filename = options$path_to_doc, fileout = png_file, width = width, row = options$row)
  } else if (!file.exists(png_file) && is_webshotable) {
    webshot2::webshot(options$path_to_doc, vwidth = width,
      file = png_file, cliprect = "viewport")
  }

  img_code <- sprintf("![](%s)\n\n", png_file)
  lnk_code <- sprintf("::: {.office-download-link}\n\n[%s](%s)\n\n:::\n\n", options$path_to_doc, options$path_to_doc)
  return(paste0(img_code, lnk_code))
}

currentState <- function() {
  list(globals = ls(.GlobalEnv),
       search = search())
}

resetSession <- function(state = .initial_state) {
  # Clean up the search list
  for (n in setdiff(search(), state$search)) {
    detach(n, character.only = TRUE)
  }

  # Clean up the global environment by deleting everything
  # that wasn't there when `state` was constructed.
  # Objects whose name starts with "." are not deleted.

  rm(list = setdiff(ls(.GlobalEnv), state$globals),
     envir = .GlobalEnv)
}

opts_chunk$set(
  echo = TRUE,
  fig.path = "static/img/figs/",
  dev="ragg_png",
  message = FALSE,
  dpi = 150,
  comment = NA)

knit_hooks$set(link_preview = function(before, options, envir) {
  if (!before && is_truthy(options$link_preview)){
    return(process_link_preview_options(options))
  }
})

if (!exists(".initial_state")) {
  .initial_state <- currentState()
}
```

# About

## Introduction

In this book we present various aspects of creating tables with the `R` language
to analyze and report clinical trials data. The book is initiated by the
R Consortium working group *R Tables for Regulatory Submissions (RTRS)*.

The R Consortium working group *R Tables for Regulatory Submissions (RTRS)* includes
representation from several large pharmaceutical companies and CRO’s. The goal
of the working group is to create standards for creating tables that meet the
requirements of FDA submission documents, and hence enhance the suitability of R
for FDA submissions. It is part of a larger R Consortium effort to facilitate
the certification and validation of R packages and tools for FDA submissions
thereby allowing drug developers to submit documentation for regulatory approval
using the R programming environment in conjunction with open-source packages
without the need for closed and often expensive proprietary tools.


## Call for Contributions

The content of this book is intended to grow via community contribution, so please
add your subject matter expertise to this content by cloning the [github repository of this book](https://github.com/RConsortium/rtrs-wg) and make a pull request with your changes.

We welcome all contribution, including but not limited to:

 - summarizing table packages 
 - adding new example tables
 - clarifying requirements and analyses
 - improving R code

In case you are new to using git and GitHub but would like to make a
contribution then please write a GitHub issue and we will reach out to you to
add the content.


The most convenient way to get started is to:

  - clone the [GitHub repository of this book](https://github.com/RConsortium/rtrs-wg)
  - install the [RStudio IDE](https://www.rstudio.com/products/rstudio/download/)
  - Open the RStudio project in `rtrs-wg/tables-book/tables-book.Rproj`
  - start working, see the [Bookdown documentation](https://bookdown.org/yihui/bookdown/), you can develop the book with the `bookdown::serve_book()` call.
  - once ready to share your work [create a PR](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/creating-a-pull-request)
  - use [GitHub issues](https://github.com/RConsortium/rtrs-wg/issues) to communicate with us if you have difficulties


## Data Used For Examples

We use synthetic data for the examples in this book. The data is available from the
`random.cidsc.data` R package which contains a number of datasets that follow the 
[CDISC ADaM specifications](https://www.cdisc.org/standards/foundational/adam).

```{r, eval=FALSE}
remotes::install_github("insightsengineering/random.cdisc.data")
```

The data in `random.cdisc.data` is completely synthetic, meaning no patient data
has been used to create it. The data is also fairly basic, meaning real study 
data often has more signal and patterns.

```{r}
data(package="random.cdisc.data")$results[, "Item"]
```

In this document, the prepending `c` stands for caches. So, for example the cached 
synthetic subject level dataset `ADSL`:

```{r}
data("cadsl", package = "random.cdisc.data")
head(cadsl)

adsl <- cadsl
```



## Installing the R packages

At some point we may switch to `renv` to install the `R` packages used 
for this book. For right now you can install the packages yourself with:

```{r, eval = FALSE}
install.packages(c("rtables", "gt", "remotes", "tidyverse", "bookdown", "r2rtf"))
install.packages('flextable', repos = 'https://davidgohel.r-universe.dev')

remotes::install_github("insightsengineering/random.cdisc.data")
remotes::install_github("insightsengineering/scda")
remotes::install_github("insightsengineering/nestcolor")
remotes::install_github("insightsengineering/tern", ref = "v0.7.10")
remotes::install_github("dmurdoch/tables")
```

In each of the sections below, we will reset R to close to the
present state
at the start of the section, so readers can execute the demonstration
code more or less independently of the other sections.  This is done using
the functions defined below.  In your own documents, you wouldn't 
need these resets.

```{r include=FALSE}
# Get the list of attached packages and global environment objects
.initial_state <- currentState()
```


<!--chapter:end:index.Rmd-->

```{r include=FALSE, cache=FALSE}
library(knitr)
library(magrittr)
library(ragg)
library(random.cdisc.data)

is_doconvable <- require("doconv") && locatexec::exec_available("word")
is_webshotable <- require("webshot2")

is_truthy <- function(x) {
  if (inherits(x, "try-error"))
    return(FALSE)
  if (!is.atomic(x))
    return(TRUE)
  if (is.null(x))
    return(FALSE)
  if (length(x) == 0)
    return(FALSE)
  if (all(is.na(x)))
    return(FALSE)
  if (is.character(x) && !any(nzchar(stats::na.omit(x))))
    return(FALSE)
  if (is.logical(x) && !any(stats::na.omit(x)))
    return(FALSE)
  return(TRUE)
}

process_link_preview_options  <- function(options){
  if(!is_truthy(options$link_preview)) return("")
  if(!options$link_preview) return("")
  if(!is_truthy(options$path_to_doc)) return("")

  png_file <- gsub("\\.(pptx|docx|pdf|html)$", ".png", options$path_to_doc)
  width <- options$width
  if(is.null(width)) {
    if(!grepl("\\.pptx$", options$path_to_doc)) width <- 650
    else width <- 750
  }

  if(!file.exists(png_file) && is_doconvable && grepl("\\.docx$", options$path_to_doc)) {
    doconv::to_miniature(filename = options$path_to_doc, fileout = png_file, width = width, row = options$row)
  } else if(!file.exists(png_file) && is_doconvable && grepl("\\.pdf$", options$path_to_doc)) {
    doconv::to_miniature(filename = options$path_to_doc, fileout = png_file, width = width, row = options$row)
  } else if(!file.exists(png_file) && is_doconvable && grepl("\\.pptx$", options$path_to_doc)) {
    doconv::to_miniature(filename = options$path_to_doc, fileout = png_file, width = width, row = options$row)
  } else if (!file.exists(png_file) && is_webshotable) {
    webshot2::webshot(options$path_to_doc, vwidth = width,
      file = png_file, cliprect = "viewport")
  }

  img_code <- sprintf("![](%s)\n\n", png_file)
  lnk_code <- sprintf("::: {.office-download-link}\n\n[%s](%s)\n\n:::\n\n", options$path_to_doc, options$path_to_doc)
  return(paste0(img_code, lnk_code))
}

currentState <- function() {
  list(globals = ls(.GlobalEnv),
       search = search())
}

resetSession <- function(state = .initial_state) {
  # Clean up the search list
  for (n in setdiff(search(), state$search)) {
    detach(n, character.only = TRUE)
  }

  # Clean up the global environment by deleting everything
  # that wasn't there when `state` was constructed.
  # Objects whose name starts with "." are not deleted.

  rm(list = setdiff(ls(.GlobalEnv), state$globals),
     envir = .GlobalEnv)
}

opts_chunk$set(
  echo = TRUE,
  fig.path = "static/img/figs/",
  dev="ragg_png",
  message = FALSE,
  dpi = 150,
  comment = NA)

knit_hooks$set(link_preview = function(before, options, envir) {
  if (!before && is_truthy(options$link_preview)){
    return(process_link_preview_options(options))
  }
})

if (!exists(".initial_state")) {
  .initial_state <- currentState()
}
```
# Overview table R packages {#tablepkgs}

We summarize various `R` packages (ordered alphabetically) to 
create production-ready tables in clinical research. 
The list is by no means complete; if you know another package that has been useful for you to
create tables or listing using clinical trial data. 
Please contribute to this chapter.


## gt

The `gt` package [@R-gt, [website](https://gt.rstudio.com/)] provides
a high-level and declarative interface for composing tables. 
Contains a variety of `formatter` functions for transforming cell values
from an input data frame to the desired reporting values (combines mutation and
aesthetic styling with options for: scientific notation, uncertainty, ranges,
percentages, suffixes, localized currency, etc.). Multiple output formats are
supported with the same declarative interface (e.g., HTML, LaTeX/PDF, and RTF).

## r2rtf

The `r2rtf` package [@R-r2rtf, [website](https://merck.github.io/r2rtf/)]
creates production-ready tables and figures in RTF format. 
The R package is designed to

- provide simple “verb” functions that correspond to each component of a table, to help you translate data frame(s) to a table in RTF file.
- enables pipes (%>%).
- only focus on table format.
- Data manipulation and analysis 
shall be handled by other R packages. (e.g., tidyverse)
minimizes package dependency

Chapter 1-9 of [The R for Clinical Study Reports and Submission](https://r4csr.org/) book 
provides examples by using `r2rtf` package. 


## rtables

The `rtables` package [@R-rtables] defines a pipe-able grammar for declaring complex table
structure layouts via nested splitting - in row- and column-space - and the
specification of analysis functions which will calculate cell values within that
structure. These pre-data table layouts are then applied to data to build the
table, during which all necessary data grouping implied by the row and column
splits, cell value calculation, and tabulation occurs automatically. Additional
table features such as titles, footers, and referential footnotes are supported.
ASCII, HTML, and PDF are supported as output formats for rendering tables.

`rtables` source code is on [GitHub](https://github.com/roche/rtables) as well
as the [documentation](https://roche.github.io/rtables/). `rtables` is also available
on [CRAN](https://CRAN.R-project.org/package=rtables).

## flextable

`flextable` [@R-flextable] is providing a *grammar* for creating and customizing tables. The
following formats are supported: 'Word' (*.docx), 'PowerPoint' (*.pptx), 'PDF'
,'HTML' and R 'Grid Graphics'. The syntax is the same for the user regardless of
the type of output to be produced. A set of functions allows the creation,
definition of cell arrangement, addition of headers or footers, formatting and
definition of cell content (i.e. text and or images). The package also offers a
set of high-level functions that allow, for example, tabular reporting of
statistical models and the creation of complex cross tabulations.

Source code is on [GitHub](https://github.com/davidgohel/flextable), a 
[user manual](https://ardata-fr.github.io/flextable-book/) is available. 
`flextable` is available on [CRAN](https://CRAN.R-project.org/package=flextable).

## tfrmt

The `tfrmt` ([website](https://gsk-biostatistics.github.io/tfrmt/)) package 
provides a language for defining display-related metadata and table formatting 
before any data is available. This package offers an intuitive interface for 
defining and layering standard or custom formats, to which ARD (analysis 
results data) is supplied. It also presents the novel ability to easily 
generate mock displays using metadata that will be used for the actual 
displays. `tfrmt` is built on top of the `gt` package, which is intended to 
support a variety of output formats in the future. Table features (titles, 
header, footnotes, etc.) as well as specific formatting (e.g. rounding, 
scientific notation, alignment, spacing) are supported.

`tfrmt` source code is on [GitHub](https://github.com/GSK-Biostatistics/tfrmt). 
`tfrmt` is also available on [CRAN](https://CRAN.R-project.org/package=tfrmt).

## tables

The `tables` package [@R-tables] provides a formula-driven interface for
computing the contents of tables and formatting them.  It was 
inspired by `SAS PROC TABULATE`, but is not compatible with it.

The user computes a table object by specifying a formula, with the
left-hand
side giving the rows, and the right-hand side giving the columns;
the formula describes the summary functions to apply and how to
organize them.  The objects can be subsetted or combined
using matrix-like operations.  Tables can
be rendered in plain text, LaTeX code to appear
in a PDF document, or HTML code for a web document.

The package is on CRAN.  Source is maintained on R-forge
at https://r-forge.r-project.org/projects/tables/ and mirrored on
Github at https://github.com/rforge/tables/.  Vignettes in the package
serve as a user manual.  Browse them at https://rdrr.io/cran/tables/, or install the package, then run
`browseVignettes(package = "tables")`.

```{r echo = FALSE}
if (!requireNamespace("tables", quietly = TRUE) ||
    packageVersion("tables") < "0.9.10")
  stop("This document requires tables version 0.9.10 or higher.")
```

```{r include=FALSE}
# automatically create a bib database for R packages
knitr::write_bib(c(
  "gt", "r2rtf", "rtables", "flextable", "tables"
), 'packages.bib')
```

<!--chapter:end:02-table-packages.Rmd-->

```{r include=FALSE, cache=FALSE}
library(knitr)
library(magrittr)
library(ragg)
library(random.cdisc.data)

is_doconvable <- require("doconv") && locatexec::exec_available("word")
is_webshotable <- require("webshot2")

is_truthy <- function(x) {
  if (inherits(x, "try-error"))
    return(FALSE)
  if (!is.atomic(x))
    return(TRUE)
  if (is.null(x))
    return(FALSE)
  if (length(x) == 0)
    return(FALSE)
  if (all(is.na(x)))
    return(FALSE)
  if (is.character(x) && !any(nzchar(stats::na.omit(x))))
    return(FALSE)
  if (is.logical(x) && !any(stats::na.omit(x)))
    return(FALSE)
  return(TRUE)
}

process_link_preview_options  <- function(options){
  if(!is_truthy(options$link_preview)) return("")
  if(!options$link_preview) return("")
  if(!is_truthy(options$path_to_doc)) return("")

  png_file <- gsub("\\.(pptx|docx|pdf|html)$", ".png", options$path_to_doc)
  width <- options$width
  if(is.null(width)) {
    if(!grepl("\\.pptx$", options$path_to_doc)) width <- 650
    else width <- 750
  }

  if(!file.exists(png_file) && is_doconvable && grepl("\\.docx$", options$path_to_doc)) {
    doconv::to_miniature(filename = options$path_to_doc, fileout = png_file, width = width, row = options$row)
  } else if(!file.exists(png_file) && is_doconvable && grepl("\\.pdf$", options$path_to_doc)) {
    doconv::to_miniature(filename = options$path_to_doc, fileout = png_file, width = width, row = options$row)
  } else if(!file.exists(png_file) && is_doconvable && grepl("\\.pptx$", options$path_to_doc)) {
    doconv::to_miniature(filename = options$path_to_doc, fileout = png_file, width = width, row = options$row)
  } else if (!file.exists(png_file) && is_webshotable) {
    webshot2::webshot(options$path_to_doc, vwidth = width,
      file = png_file, cliprect = "viewport")
  }

  img_code <- sprintf("![](%s)\n\n", png_file)
  lnk_code <- sprintf("::: {.office-download-link}\n\n[%s](%s)\n\n:::\n\n", options$path_to_doc, options$path_to_doc)
  return(paste0(img_code, lnk_code))
}

currentState <- function() {
  list(globals = ls(.GlobalEnv),
       search = search())
}

resetSession <- function(state = .initial_state) {
  # Clean up the search list
  for (n in setdiff(search(), state$search)) {
    detach(n, character.only = TRUE)
  }

  # Clean up the global environment by deleting everything
  # that wasn't there when `state` was constructed.
  # Objects whose name starts with "." are not deleted.

  rm(list = setdiff(ls(.GlobalEnv), state$globals),
     envir = .GlobalEnv)
}

opts_chunk$set(
  echo = TRUE,
  fig.path = "static/img/figs/",
  dev="ragg_png",
  message = FALSE,
  dpi = 150,
  comment = NA)

knit_hooks$set(link_preview = function(before, options, envir) {
  if (!before && is_truthy(options$link_preview)){
    return(process_link_preview_options(options))
  }
})

if (!exists(".initial_state")) {
  .initial_state <- currentState()
}
```

# Formatting and Rendering Tables

Table generation usually is a two step process

1. Derive the cell value and tabulate them.
1. Create the final table output, save it to a file to be shared with collaborators. 

Chapter [Commonly Used Tables] focuses with the work involved in 1, in this chapter we
discuss the various aspects of creating the final outputs that is commonly stored
in a file with a particular file format (`pdf`, `txt`, `html`, `docx` or `rtf`).

## Title & Footnotes

Commonly rendered tables that are reported to the health authorities have titles
and footnotes with information such as:

- what is summarized in the table
- database lock date
- patient sub-population
- notes by study team
- notes regarding statistical algorithms chosen
- provenance information including path to program and when the table was created

Often footnotes include cell references.

### Title and Footnotes in rtables

The `basic_table` function in `rtables` has the argument `titles`, `subtitles`,
`main_footer`, `prov_footer` to add titles and footnotes to tables. `rtables`
also supports referential footnotes.

So for example a basic demographics table created with `rtables` via `tern` with
title and footnotes would look as follows:

```{r, comment=NA }
resetSession()
library(rtables)

lyt <- basic_table(
  title = "Demographic Table - All Patients",
  subtitles = c("Cutoff Date: June 01, 2022", "Arm B received a placebo."),
  main_footer = c("Missing data is omitted.")
) |>
  split_cols_by("ARM") |>
  analyze(c("AGE", "SEX"))

build_table(lyt, adsl)
```

### Title and Footnotes in flextable

Titles and notes can be added and formatted with the 'flextable' package. It is possible to add them in the header and in the footer. Several methods are possible but for most needs, the `add_header_lines()` and `add_footer_lines()` functions will be the easiest to use.

Let's create first a flextable from an aggregation that 
will be used to illustrate the features.

```{r message=FALSE}
resetSession()
library(flextable)
library(dplyr)

z <- adsl |> 
  group_by(ARM, SEX) |>
  summarise(avg = mean(AGE), sd = sd(AGE)) |>
  tabulator(rows = "SEX", columns = "ARM",
    Y = as_paragraph(avg, " (", sd, ")")) |> 
  as_flextable()
z
```

The following shows how to add titles or notes:

```{r}
z |>
  add_header_lines("hello world") |>
  add_footer_lines("bye bye world")
```

For Word output, users can prepend a table number that will auto-incremente.

```{r}
docx_file <- "reports/flextable-title-01.docx"
ft <- add_header_lines(z, "hello world") |>
  prepend_chunks(
    i = 1, j = 1, part = "header", 
    as_chunk("Table "), as_word_field("SEQ tab \u005C* Arabic"), 
    as_chunk(": ")) |>
  add_footer_lines("bye bye world") |>
  theme_vanilla()
save_as_docx(ft, ft, path = docx_file)
```


```{r echo=FALSE, link_preview=TRUE, path_to_doc = "reports/flextable-title-01.docx"}
```

Footnotes are also available in 'flextable' with function `footnote()`. 
The function lets users add footnotes and references to it on the table.


```{r}
footnote(z, i = c(1, 2, 2), j = c(1, 5, 7), 
         value = as_paragraph("hello world"), ref_symbols = "(1)")
```

### Titles and footnotes in tables

The `tables` package concentrates on the table itself.  The titles
are generally written as part of the surrounding document.  Footnotes
would be added after constructing the table by modifying 
individual entries.

Alternatively for HTML output, only the footnote
markers need to be added by modifying entries, and then
the footnotes can be applied by using `toHTML(tab, options = list(doFooter = TRUE, 
HTMLfooter = HTMLfootnotes(...))`.

```{r}
resetSession()
adsl <- cadsl

library(tables)
table_options(doCSS = TRUE)

sd_in_parens <- function(x) sprintf("(%.1f)", sd(x))

tab <- tabular(SEX ~ Heading()*ARM*
                     Heading()*AGE*
                     Heading()*(mean + sd_in_parens), 
               data = adsl)

rowLabels(tab)[1,1] <- paste(rowLabels(tab)[1,1], "<sup>a</sup>")
tab[2,2] <- sprintf("%s%s", tab[2,2], "<sup>b</sup>")
tab[2,3] <- sprintf("%.2f%s", tab[2,3], "<sup>b</sup>")

footnotes <- HTMLfootnotes(tab, a = "This is a label footnote.",
                                b = "These are cell footnotes.")
toHTML(tab, options = list(HTMLfooter = footnotes,
                           doFooter = TRUE))
```

## Captions

A caption is a single paragraph of text describing the table it
is associated to. Captions are often used because they allow you to
cross-reference tables or list them in a 'list of tables' with the corresponding
page numbers.

### Captions in flextable

The `set_caption()` function in 'flextable' is the recommanded way to add
captions. 

```{r}
resetSession()
library(flextable)

flextable(head(cars)) |>
  set_caption(
    caption = "a caption",
    autonum = officer::run_autonum(seq_id = "tab", bkm = "flextable-label"))
```

In bookdown, use the syntax `\@ref(tab:flextable-label)` to create a linked 
reference to the table. See an example of a reference: \@ref(tab:flextable-label).

With 'Quarto', the R chunk code should be transformed as: 

````r
#| label: tbl-flextable-label
#| tbl-cap: a caption
flextable(head(cars))
````

### Captions in tables

As with titles, captions would be added as part of the
surrounding document rather than part of the table object.

## Pagination

Historically tables have been printed to paper for submissions. Hence large tables
that would not fit onto a single printed page (e.g. letter & portrait) would have to 
be split into multiple tables that can be printed to the preferred page size. This 
process of splitting the table is called *pagination* of tables.

Pagination is a complex task as it requires to repeat information so that the tables
on each page are correct tables with all relevant information for context.

### Pagination in rtables

In `rtables` pagination can be done with the `paginate_table` function which has 
a number of arguments to split the table, see the [example documentation](https://roche.github.io/rtables/reference/paginate.html).

### Pagination in flextable

In 'flextable', there is no concept of pagination. The recommended method is to
create a flextable for each modality of a group and to separate them with a page
break; from R, this implies looping over a set of modalities with a `for`
statement or a call to the `lapply()` function. 

Note this concept of page break is only valid for paginated documents, i.e.
Word, PDF, eventually HTML with
[paged.js](https://pagedjs.org/made-with-paged.js.html) formats. 

In an 'R Markdown' document, the markdown code to insert a page break is
`\newpage`; with the package 'officer', you have to use `body_add_break()` (for
Word documents only).

### Pagination in tables

Tables that span multiple pages are supported in PDF output using
the LaTeX `longtable` package, specified when converting to LaTeX.



## Rendering Tables

The choice of file format is often dictated by your company's processes to 
include the tables in a report.

### ASCII

### PDF

### HTML

### WORD

### RTF



<!--chapter:end:03-formatting-rendering.Rmd-->

```{r include=FALSE, cache=FALSE}
library(knitr)
library(magrittr)
library(ragg)
library(random.cdisc.data)

is_doconvable <- require("doconv") && locatexec::exec_available("word")
is_webshotable <- require("webshot2")

is_truthy <- function(x) {
  if (inherits(x, "try-error"))
    return(FALSE)
  if (!is.atomic(x))
    return(TRUE)
  if (is.null(x))
    return(FALSE)
  if (length(x) == 0)
    return(FALSE)
  if (all(is.na(x)))
    return(FALSE)
  if (is.character(x) && !any(nzchar(stats::na.omit(x))))
    return(FALSE)
  if (is.logical(x) && !any(stats::na.omit(x)))
    return(FALSE)
  return(TRUE)
}

process_link_preview_options  <- function(options){
  if(!is_truthy(options$link_preview)) return("")
  if(!options$link_preview) return("")
  if(!is_truthy(options$path_to_doc)) return("")

  png_file <- gsub("\\.(pptx|docx|pdf|html)$", ".png", options$path_to_doc)
  width <- options$width
  if(is.null(width)) {
    if(!grepl("\\.pptx$", options$path_to_doc)) width <- 650
    else width <- 750
  }

  if(!file.exists(png_file) && is_doconvable && grepl("\\.docx$", options$path_to_doc)) {
    doconv::to_miniature(filename = options$path_to_doc, fileout = png_file, width = width, row = options$row)
  } else if(!file.exists(png_file) && is_doconvable && grepl("\\.pdf$", options$path_to_doc)) {
    doconv::to_miniature(filename = options$path_to_doc, fileout = png_file, width = width, row = options$row)
  } else if(!file.exists(png_file) && is_doconvable && grepl("\\.pptx$", options$path_to_doc)) {
    doconv::to_miniature(filename = options$path_to_doc, fileout = png_file, width = width, row = options$row)
  } else if (!file.exists(png_file) && is_webshotable) {
    webshot2::webshot(options$path_to_doc, vwidth = width,
      file = png_file, cliprect = "viewport")
  }

  img_code <- sprintf("![](%s)\n\n", png_file)
  lnk_code <- sprintf("::: {.office-download-link}\n\n[%s](%s)\n\n:::\n\n", options$path_to_doc, options$path_to_doc)
  return(paste0(img_code, lnk_code))
}

currentState <- function() {
  list(globals = ls(.GlobalEnv),
       search = search())
}

resetSession <- function(state = .initial_state) {
  # Clean up the search list
  for (n in setdiff(search(), state$search)) {
    detach(n, character.only = TRUE)
  }

  # Clean up the global environment by deleting everything
  # that wasn't there when `state` was constructed.
  # Objects whose name starts with "." are not deleted.

  rm(list = setdiff(ls(.GlobalEnv), state$globals),
     envir = .GlobalEnv)
}

opts_chunk$set(
  echo = TRUE,
  fig.path = "static/img/figs/",
  dev="ragg_png",
  message = FALSE,
  dpi = 150,
  comment = NA)

knit_hooks$set(link_preview = function(before, options, envir) {
  if (!before && is_truthy(options$link_preview)){
    return(process_link_preview_options(options))
  }
})

if (!exists(".initial_state")) {
  .initial_state <- currentState()
}
```
# Commonly Used Tables {#commontables}


<!--chapter:end:04-00-common-tables.Rmd-->

---
output: html_document
editor_options: 
  chunk_output_type: console
---
```{r include=FALSE, cache=FALSE}
library(knitr)
library(magrittr)
library(ragg)
library(random.cdisc.data)

is_doconvable <- require("doconv") && locatexec::exec_available("word")
is_webshotable <- require("webshot2")

is_truthy <- function(x) {
  if (inherits(x, "try-error"))
    return(FALSE)
  if (!is.atomic(x))
    return(TRUE)
  if (is.null(x))
    return(FALSE)
  if (length(x) == 0)
    return(FALSE)
  if (all(is.na(x)))
    return(FALSE)
  if (is.character(x) && !any(nzchar(stats::na.omit(x))))
    return(FALSE)
  if (is.logical(x) && !any(stats::na.omit(x)))
    return(FALSE)
  return(TRUE)
}

process_link_preview_options  <- function(options){
  if(!is_truthy(options$link_preview)) return("")
  if(!options$link_preview) return("")
  if(!is_truthy(options$path_to_doc)) return("")

  png_file <- gsub("\\.(pptx|docx|pdf|html)$", ".png", options$path_to_doc)
  width <- options$width
  if(is.null(width)) {
    if(!grepl("\\.pptx$", options$path_to_doc)) width <- 650
    else width <- 750
  }

  if(!file.exists(png_file) && is_doconvable && grepl("\\.docx$", options$path_to_doc)) {
    doconv::to_miniature(filename = options$path_to_doc, fileout = png_file, width = width, row = options$row)
  } else if(!file.exists(png_file) && is_doconvable && grepl("\\.pdf$", options$path_to_doc)) {
    doconv::to_miniature(filename = options$path_to_doc, fileout = png_file, width = width, row = options$row)
  } else if(!file.exists(png_file) && is_doconvable && grepl("\\.pptx$", options$path_to_doc)) {
    doconv::to_miniature(filename = options$path_to_doc, fileout = png_file, width = width, row = options$row)
  } else if (!file.exists(png_file) && is_webshotable) {
    webshot2::webshot(options$path_to_doc, vwidth = width,
      file = png_file, cliprect = "viewport")
  }

  img_code <- sprintf("![](%s)\n\n", png_file)
  lnk_code <- sprintf("::: {.office-download-link}\n\n[%s](%s)\n\n:::\n\n", options$path_to_doc, options$path_to_doc)
  return(paste0(img_code, lnk_code))
}

currentState <- function() {
  list(globals = ls(.GlobalEnv),
       search = search())
}

resetSession <- function(state = .initial_state) {
  # Clean up the search list
  for (n in setdiff(search(), state$search)) {
    detach(n, character.only = TRUE)
  }

  # Clean up the global environment by deleting everything
  # that wasn't there when `state` was constructed.
  # Objects whose name starts with "." are not deleted.

  rm(list = setdiff(ls(.GlobalEnv), state$globals),
     envir = .GlobalEnv)
}

opts_chunk$set(
  echo = TRUE,
  fig.path = "static/img/figs/",
  dev="ragg_png",
  message = FALSE,
  dpi = 150,
  comment = NA)

knit_hooks$set(link_preview = function(before, options, envir) {
  if (!before && is_truthy(options$link_preview)){
    return(process_link_preview_options(options))
  }
})

if (!exists(".initial_state")) {
  .initial_state <- currentState()
}
```

## Demographic Tables

### rtables

Using `rtables` only:

```{r, comment= NA}
resetSession()
library(rtables)

a_demo_num <- function(x) {
    in_rows(n = length(x),
            "Mean (SD)" = rcell(c(mean(x, na.rm = TRUE),
                                  sd(x, na.rm=TRUE)), format = "xx.x (xx.x)"),
            "Median" = median(x,na.rm = TRUE),
            "Min - Max" = rcell(range(x, na.rm = TRUE), format = "xx.x - xx.x"))
}

a_demo_fac <- function(x) {
    in_rows(.list = c(c(n = length(x)), table(x)))
}

lyt <- basic_table(title = "x.x: Study Subject Data",
                   subtitles= c("x.x.x: Demographic Characteristics",
                                "Table x.x.x.x: Demographic Characteristics - Full Analysis Set"),
                   prov_footer = "Source: ADSL DDMMYYYY hh:mm; Listing x.xx; SDTM package: DDMMYYYY") |>
  split_cols_by("ARM") |>
  analyze(c("AGE", "SEX", "COUNTRY"), afun = list(AGE = a_demo_num, SEX = a_demo_fac,
                                                  COUNTRY = a_demo_fac))
 
build_table(lyt, ex_adsl)
```

Using `rtables` and `tern`

```{r, comment=NA}
library(tern)
lyt <- basic_table(title = "x.x: Study Subject Data",
                   subtitles= c("x.x.x: Demographic Characteristics",
                                "Table x.x.x.x: Demographic Characteristics - Full Analysis Set"),
                   prov_footer = "Source: ADSL DDMMYYYY hh:mm; Listing x.xx; SDTM package: DDMMYYYY") |>
  split_cols_by("ARM") |>
  summarize_vars(c("AGE", "SEX", "COUNTRY"))

build_table(lyt, ex_adsl)
```


### gt

```{r, comment= NA}
resetSession()
library(gt)
library(tidyverse)

# We will use ex_adsl but will assign a unit to the Age column

ex_adsl <- formatters::ex_adsl
gt_adsl <- ex_adsl
attr(gt_adsl$AGE, "units") <- "Years"

# This is a customized summary function
# It creates numeric and categorical summaries for specified variables, following the rtables exmaple

custom_summary <- function(df, group_var, sum_var){
  group_var <- rlang::ensym(group_var)
  sum_var <- rlang::ensym(sum_var)
  
  is_categorical <- is.character(eval(expr(`$`(df, !!sum_var)))) | is.factor(eval(expr(`$`(df, !!sum_var)))) 
  
  if (is_categorical){
    df <- df %>% 
      dplyr::group_by(!!group_var) %>% 
      dplyr::mutate(N = n()) %>% 
      dplyr::ungroup() %>% 
      dplyr::group_by(!!group_var, !!sum_var) %>% 
      dplyr::summarize(val = n(),
                       sd = 100*n()/mean(N)) %>% 
      dplyr::ungroup() %>% 
      tidyr::pivot_wider(id_cols = !!sum_var, names_from = !!group_var, values_from = c(val, sd)) %>% 
      dplyr::rename(label = !!sum_var) %>% 
      dplyr::mutate(isnum = FALSE,
                    across(where(is.numeric), ~ifelse(is.na(.), 0, .))) 
    
    sum_unit <- ", n (%)"
    
  } else {
    
    sum_unit <- sprintf(" (%s)", attr(eval(expr(`$`(df, !!sum_var))), "units"))
    
    df <- df %>% 
      dplyr::group_by(!!group_var) %>% 
      dplyr::summarize(n = sum(!is.na(!!sum_var)),
                       mean = mean(!!sum_var, na.rm = TRUE),
                       sd = sd(!!sum_var, na.rm = TRUE),
                       median = median(!!sum_var, na.rm = TRUE),
                       min = min(!!sum_var, na.rm = TRUE),
                       max = max(!!sum_var, na.rm = TRUE),
                       min_max = NA) %>% 
      dplyr::ungroup() %>% 
      tidyr::pivot_longer(cols = c(n, mean, median, min_max), names_to = "label", values_to = "val") %>% 
      dplyr::mutate(sd = ifelse(label == "mean", sd, NA),
                max = ifelse(label == "min_max", max, NA),
                min = ifelse(label == "min_max", min, NA),
                label = dplyr::recode(label, "mean" = "Mean (SD)", "min_max" = "Min - Max", "median" = "Median")) %>% 
      tidyr::pivot_wider(id_cols = label, names_from = !!group_var, values_from = c(val, sd, min, max)) %>% 
      dplyr::mutate(isnum = TRUE)
    
  }
  
  df %>% 
    dplyr::mutate(category = paste0(stringr::str_to_title(deparse(substitute(!!sum_var))),
                                     sum_unit)) 
}

# Perform aggregation for variables Age, Sex and Country

adsl_summary <- purrr::map_df(.x = vars(AGE, SEX, COUNTRY),
                             .f = ~custom_summary(df = gt_adsl, group_var = ARM, sum_var = !!.x)) 

# Count number of patients per Arm

total_n_arm <- ex_adsl %>% 
  dplyr::group_by(ARM) %>% 
  dplyr::summarise(N = n()) %>% 
  dplyr::ungroup() 

# gt

gt(adsl_summary, 
   rowname_col = "label",
   groupname_col = "category") %>%
  tab_header(
    title = "x.x: Study Subject Data",
    subtitle = html("x.x.x: Demographic Characteristics<br>Table x.x.x.x: Demographic Characteristics - Full Analysis Set"),
    preheader = c("Protocol: XXXXX", "Cutoff date: DDMMYYYY")
  ) %>% 
  tab_source_note("Source: ADSL DDMMYYYY hh:mm; Listing x.xx; SDTM package: DDMMYYYY") %>% 
  opt_align_table_header(align = "left") %>% 
  fmt_integer(columns = starts_with(c("val", "min", "max")), rows = label != "Mean (SD)") %>% 
  fmt_number(columns = starts_with(c("val", "sd")), rows = label == "Mean (SD)", decimals = 1) %>% 
  fmt_number(columns = starts_with("sd"), rows = isnum == FALSE, decimals = 1) %>% 
  sub_missing(missing_text = "") %>% 
  summary_rows(groups = c("Sex, n (%)", "Country, n (%)"),
               columns = starts_with("val"),
               fns = list(n = ~sum(.)),
               missing_text = "",
               formatter = fmt_integer) %>% 
  cols_merge_n_pct(col_n = "val_A: Drug X", col_pct = "sd_A: Drug X") %>% 
  cols_merge_n_pct(col_n = "val_B: Placebo", col_pct = "sd_B: Placebo") %>% 
  cols_merge_n_pct(col_n = "val_C: Combination", col_pct = "sd_C: Combination") %>% 
  cols_merge_range(col_begin = "min_A: Drug X", col_end = "max_A: Drug X", sep = " - ") %>% 
  cols_merge_range(col_begin = "min_B: Placebo", col_end = "max_B: Placebo", sep = " - ") %>% 
  cols_merge_range(col_begin = "min_C: Combination", col_end = "max_C: Combination", sep = " - ") %>% 
  cols_merge(columns = c("val_A: Drug X", "min_A: Drug X"), pattern = "{1}{2}") %>% 
  cols_merge(columns = c("val_B: Placebo", "min_B: Placebo"), pattern = "{1}{2}") %>% 
  cols_merge(columns = c("val_C: Combination", "min_C: Combination"), pattern = "{1}{2}") %>% 
  cols_hide(columns = isnum) %>% 
  cols_align(align = c("center"),
             columns = c("val_A: Drug X", "val_B: Placebo", "val_C: Combination")) %>% 
  cols_align(align = "center",
             columns = 1) %>% 
  cols_label("val_A: Drug X" = html(sprintf("A: Drug X<br> N=%i (100%%)", total_n_arm$N[1])),
             "val_B: Placebo" = html(sprintf("B: Placebo<br> N=%i (100%%)", total_n_arm$N[2])),
             "val_C: Combination" = html(sprintf("C: Combination<br> N=%i (100%%)", total_n_arm$N[3]))) %>% 
  tab_options(
    table.font.size = 9,
    page.orientation = "landscape",
    page.numbering = TRUE,
    page.header.use_tbl_headings = TRUE,
    page.footer.use_tbl_notes = TRUE)
```

### flextable



```{r}
# The two steps in creating 'Demographic Tables' are:
# 
# - summarize the information with the `flextable::summarizor()` function. 
# It computes a set of statistics for each variable by groups. It returns 
# a data.frame ready to be used by `flextable::as_flextable()`.
# - Create the flextable with the `as_flextable()` function.

resetSession()
ex_adsl <- formatters::ex_adsl

library(flextable)
library(tidyverse)
library(officer)

set_flextable_defaults(
  border.color = "#AAAAAA", font.family = "Open Sans",
font.size = 10, padding = 3, line_spacing = 1.4
)

# data
adsl <- select(ex_adsl, AGE, SEX, COUNTRY, ARM)

# In the illustration, we use labels from the column attributes.  

col_labels <- map_chr(adsl, function(x) attr(x, "label"))

# Now let's use the labels and customize the ‘flextable’ output.

ft <- summarizor(adsl, by = "ARM") |>
  as_flextable(sep_w = 0, separate_with = "variable", 
               spread_first_col = TRUE) |>
  align(i = ~ !is.na(variable), align = "left") |> 
  prepend_chunks(i = ~ is.na(variable), j  ="stat", as_chunk("\t") ) |> 
  labelizor(j = c("stat"), 
            labels = col_labels, part = "all") |> 
  autofit() |>
  add_header_lines(
    c("x.x: Study Subject Data",
      "x.x.x: Demographic Characteristics",
      "Table x.x.x.x: Demographic Characteristics - Full Analysis Set")) |> 
  add_footer_lines("Source: ADSL DDMMYYYY hh:mm; Listing x.xx; SDTM package: DDMMYYYY")

ft
```

### tables

The `tables` package uses a different style
than the other packages for tables such as this, where
there are separate sections for age, sex and country
breakdowns of the data.  Rather than putting
the section heading on a separate line, it normally
puts the heading in a separate column to the left
of the other columns.

```{r}
resetSession()

ex_adsl <- formatters::ex_adsl

library(tables)
table_options(doCSS = TRUE)

meansd <- function(x) sprintf("%.1f (%.1f)", mean(x), sd(x))

iqr <- function(x) quantile(x, 0.75) - quantile(x, 0.25)

medianiqr <- function(x) sprintf("%.1f (%.1f)", median(x), iqr(x))

minmax <- function(x) sprintf("%.1f - %.1f", min(x), max(x))

countpercent <- function(num, denom) 
  sprintf("%d (%.1f%%)", 
          length(num), 
          100*length(num)/length(denom))

count <- function(x) sprintf("(N=%d)", length(x))

tab <- tabular( Heading()*1*Heading()*count +
         Heading("Age (Years)")*
           AGE * (Heading("Mean (SD)")*meansd +
                  Heading("Median (IQR)")*medianiqr +
                  Heading("Min - Max")*minmax) +
         (Heading("Sex, n, (%)")*SEX +
          Heading("Country, n, (%)")*COUNTRY)*
            Heading()*Percent(denom = Equal(ARM), fn = countpercent) ~ 
         Heading()*ARM, 
         data = ex_adsl )

useGroupLabels(tab, indent = "&emsp;")
```

<!--chapter:end:04-01-demographics.Rmd-->

---
output: html_document
editor_options: 
  chunk_output_type: console
---
```{r include=FALSE, cache=FALSE}
library(knitr)
library(magrittr)
library(ragg)
library(random.cdisc.data)

is_doconvable <- require("doconv") && locatexec::exec_available("word")
is_webshotable <- require("webshot2")

is_truthy <- function(x) {
  if (inherits(x, "try-error"))
    return(FALSE)
  if (!is.atomic(x))
    return(TRUE)
  if (is.null(x))
    return(FALSE)
  if (length(x) == 0)
    return(FALSE)
  if (all(is.na(x)))
    return(FALSE)
  if (is.character(x) && !any(nzchar(stats::na.omit(x))))
    return(FALSE)
  if (is.logical(x) && !any(stats::na.omit(x)))
    return(FALSE)
  return(TRUE)
}

process_link_preview_options  <- function(options){
  if(!is_truthy(options$link_preview)) return("")
  if(!options$link_preview) return("")
  if(!is_truthy(options$path_to_doc)) return("")

  png_file <- gsub("\\.(pptx|docx|pdf|html)$", ".png", options$path_to_doc)
  width <- options$width
  if(is.null(width)) {
    if(!grepl("\\.pptx$", options$path_to_doc)) width <- 650
    else width <- 750
  }

  if(!file.exists(png_file) && is_doconvable && grepl("\\.docx$", options$path_to_doc)) {
    doconv::to_miniature(filename = options$path_to_doc, fileout = png_file, width = width, row = options$row)
  } else if(!file.exists(png_file) && is_doconvable && grepl("\\.pdf$", options$path_to_doc)) {
    doconv::to_miniature(filename = options$path_to_doc, fileout = png_file, width = width, row = options$row)
  } else if(!file.exists(png_file) && is_doconvable && grepl("\\.pptx$", options$path_to_doc)) {
    doconv::to_miniature(filename = options$path_to_doc, fileout = png_file, width = width, row = options$row)
  } else if (!file.exists(png_file) && is_webshotable) {
    webshot2::webshot(options$path_to_doc, vwidth = width,
      file = png_file, cliprect = "viewport")
  }

  img_code <- sprintf("![](%s)\n\n", png_file)
  lnk_code <- sprintf("::: {.office-download-link}\n\n[%s](%s)\n\n:::\n\n", options$path_to_doc, options$path_to_doc)
  return(paste0(img_code, lnk_code))
}

currentState <- function() {
  list(globals = ls(.GlobalEnv),
       search = search())
}

resetSession <- function(state = .initial_state) {
  # Clean up the search list
  for (n in setdiff(search(), state$search)) {
    detach(n, character.only = TRUE)
  }

  # Clean up the global environment by deleting everything
  # that wasn't there when `state` was constructed.
  # Objects whose name starts with "." are not deleted.

  rm(list = setdiff(ls(.GlobalEnv), state$globals),
     envir = .GlobalEnv)
}

opts_chunk$set(
  echo = TRUE,
  fig.path = "static/img/figs/",
  dev="ragg_png",
  message = FALSE,
  dpi = 150,
  comment = NA)

knit_hooks$set(link_preview = function(before, options, envir) {
  if (!before && is_truthy(options$link_preview)){
    return(process_link_preview_options(options))
  }
})

if (!exists(".initial_state")) {
  .initial_state <- currentState()
}
```

## Event Tables

We will use the `ex_adae` data included within the `formatters` package.

```{r, comment=NA}
head(formatters::ex_adae)
```

### Adverse Events

 

#### `rtables` Only

Adverse Events by ID

```{r, comment=NA}
resetSession()
library(rtables)

s_events_patients <- function(x, labelstr, .N_col) {
  in_rows(
    "Patients with at least one event" =
      rcell(length(unique(x)) * c(1, 1 / .N_col), format = "xx (xx.xx%)"),

    "Total number of events" = rcell(length(x), format = "xx")
  )
}

table_count_per_id <- function(df, termvar = "AEDECOD", idvar = "USUBJID") {

  x <- df[[termvar]]
  id <- df[[idvar]]

  counts <- table(x[!duplicated(id)])

  in_rows(
    .list = as.vector(counts),
    .labels = names(counts)
  )
}

lyt <- basic_table(show_colcounts = TRUE) %>%
    split_cols_by("ARM") %>%
    analyze("USUBJID", afun = s_events_patients) %>%
    split_rows_by("AEBODSYS", child_labels = "visible", 
                  split_fun = trim_levels_in_group("AEDECOD")) %>%
    summarize_row_groups("USUBJID", cfun = s_events_patients) %>%
    analyze("AEDECOD", table_count_per_id, show_labels = "hidden", indent_mod = -1)

build_table(lyt, ex_adae, alt_counts_df = ex_adsl)
```

#### flextable

```{r message=FALSE}
resetSession()
ex_adsl <- formatters::ex_adsl
ex_adae <- formatters::ex_adae
library(flextable)
library(tidyr)
library(dplyr)
library(forcats)
ae_tabulator <- function(ADSL, ADAE){
  
  
  subject_cts <- group_by(ADSL, ARM) |> 
    summarise(n_subject = n())
  
  all_event_total_cts <- group_by(ADAE, ARM) |> 
    summarise(n_usub = n_distinct(USUBJID), n_events = n())
  
  aebodsys_cts <- group_by(ADAE, ARM, AEBODSYS) |> 
    summarise(n_usub = n_distinct(USUBJID), n_events = n(),
              .groups = "drop")
  
  aedecod_cts <- group_by(ADAE, ARM, AEBODSYS, AEDECOD) |> 
    summarise(n_usub = n_distinct(USUBJID), n_events = n(),
              .groups = "drop")
  
  x <- bind_rows(all_event_total_cts, aebodsys_cts, aedecod_cts) |> 
    mutate(
      AEBODSYS = fct_expand(AEBODSYS, "ALL1") |> fct_relevel("ALL1"),
      AEDECOD = fct_expand(AEDECOD, "ALL2") |> fct_relevel("ALL2")
    ) |> 
    left_join(subject_cts, by = "ARM") |> 
    replace_na(replace = list(AEBODSYS = "ALL1", AEDECOD = "ALL2")) |>
    arrange(AEBODSYS, AEDECOD) |> 
    mutate(pct = n_usub / n_subject)
  attr(x, "ARM_COUNTS") <- setNames(subject_cts$n_subject, subject_cts$ARM)
  x
  
}

# Labels for `flextable::labelizor()`:
AEDECOD_LABELS <- c(
  ALL1 = "Patients with at least one event", 
  ALL2 = "Patients with at least one event")
HEADER_LABELS <- c(
  AEDECOD = "dictionary-derived term\n\tbody system or organ class",
  nevents = "Total number\nof events", 
  n = "n\n(% of subjects)",
  "ARM A" = "Treatment A",
  "ARM B" = "Treatment B"
)

# `tabulator()` call:
dat <- ae_tabulator(ADSL = ex_adsl, ADAE = ex_adae)
ARM_COUNTS <- attr(dat, "ARM_COUNTS")

tab <- tabulator(
  dat,
  rows = c("AEBODSYS", "AEDECOD"),
  columns = "ARM",
  `n` = as_paragraph(fmt_n_percent(n_usub, pct)),
  `nevents` = as_paragraph(n_events)
)

.ARM_COUNTS <- ARM_COUNTS

# flextable creation:

ft <- as_flextable(tab, spread_first_col = TRUE) |> 
  fontsize(size = 9, part = "all") |>
  prepend_chunks(
    i = ~ is.na(AEBODSYS), j = 1, 
    as_chunk("\t")
  )

for(ARM_COD in names(ARM_COUNTS)){
  ft <- append_chunks(
    x = ft, 
    part = "header", 
    i = 1, 
    j = tabulator_colnames(tab, columns = "n", ARM %in% !!ARM_COD),
    as_chunk(ARM_COUNTS[ARM_COD], 
             formatter = fmt_header_n)
  )
}
ft <- labelizor(
    ft, 
    j = "AEDECOD", 
    part = "body", 
    labels = AEDECOD_LABELS) |> 
  labelizor(part = "header", labels = HEADER_LABELS) |> 
  align(j = 1, align = "left") |> 
  autofit()

ft
```

#### tables

The `tables` package normally generates tables from single datasets, while this
kind of table requires information from two:  `adsl` and `ex_adae`.
One way to handle this would be to add the `adsl` patient count 
information to a copy of the `ex_adae` table.  In this code we
use a different approach:  we generate one table of patient counts
to produce the heading lines, and a second table with the adverse
event data, then use `rbind` to combine the two tables.

```{r}
resetSession()

library(tables)
table_options(doCSS = TRUE)

ex_adae <- formatters::ex_adae

subject_counts <- table(adsl$ARM)

countpercentid <- function(num, ARM) {
  n <- length(unique(num))
  sprintf("%d (%.2f%%)", 
          length(unique(num)), 
          100*n/subject_counts[ARM[1]])
}

count <- function(x) sprintf("(N=%d)", length(x))

heading <- tabular(Heading("")*1*
                     Heading("")*count ~ 
                   Heading()*ARM, data = adsl)

body <- tabular( Heading("Patients with at least one event")*1*
                   Heading("")*countpercentid*Arguments(ARM = ARM)*
                   Heading()*USUBJID +
                 Heading("Total number of events")*1*Heading("")*1 +
                 Heading()*AEBODSYS*
                   (Heading("Patients with at least one event")*
                      Percent(denom = ARM, fn = countpercentid)*
                      Heading()*USUBJID +
                    Heading("Total number of events")*1 +
                    Heading()*AEDECOD*DropEmpty()) ~ 
                 Heading()*ARM, 
                 data = ex_adae )

tab <- rbind(heading, body)
useGroupLabels(tab, indent = "&emsp;")
```

<!--chapter:end:04-02-events.Rmd-->

```{r include=FALSE, cache=FALSE}
library(knitr)
library(magrittr)
library(ragg)
library(random.cdisc.data)

is_doconvable <- require("doconv") && locatexec::exec_available("word")
is_webshotable <- require("webshot2")

is_truthy <- function(x) {
  if (inherits(x, "try-error"))
    return(FALSE)
  if (!is.atomic(x))
    return(TRUE)
  if (is.null(x))
    return(FALSE)
  if (length(x) == 0)
    return(FALSE)
  if (all(is.na(x)))
    return(FALSE)
  if (is.character(x) && !any(nzchar(stats::na.omit(x))))
    return(FALSE)
  if (is.logical(x) && !any(stats::na.omit(x)))
    return(FALSE)
  return(TRUE)
}

process_link_preview_options  <- function(options){
  if(!is_truthy(options$link_preview)) return("")
  if(!options$link_preview) return("")
  if(!is_truthy(options$path_to_doc)) return("")

  png_file <- gsub("\\.(pptx|docx|pdf|html)$", ".png", options$path_to_doc)
  width <- options$width
  if(is.null(width)) {
    if(!grepl("\\.pptx$", options$path_to_doc)) width <- 650
    else width <- 750
  }

  if(!file.exists(png_file) && is_doconvable && grepl("\\.docx$", options$path_to_doc)) {
    doconv::to_miniature(filename = options$path_to_doc, fileout = png_file, width = width, row = options$row)
  } else if(!file.exists(png_file) && is_doconvable && grepl("\\.pdf$", options$path_to_doc)) {
    doconv::to_miniature(filename = options$path_to_doc, fileout = png_file, width = width, row = options$row)
  } else if(!file.exists(png_file) && is_doconvable && grepl("\\.pptx$", options$path_to_doc)) {
    doconv::to_miniature(filename = options$path_to_doc, fileout = png_file, width = width, row = options$row)
  } else if (!file.exists(png_file) && is_webshotable) {
    webshot2::webshot(options$path_to_doc, vwidth = width,
      file = png_file, cliprect = "viewport")
  }

  img_code <- sprintf("![](%s)\n\n", png_file)
  lnk_code <- sprintf("::: {.office-download-link}\n\n[%s](%s)\n\n:::\n\n", options$path_to_doc, options$path_to_doc)
  return(paste0(img_code, lnk_code))
}

currentState <- function() {
  list(globals = ls(.GlobalEnv),
       search = search())
}

resetSession <- function(state = .initial_state) {
  # Clean up the search list
  for (n in setdiff(search(), state$search)) {
    detach(n, character.only = TRUE)
  }

  # Clean up the global environment by deleting everything
  # that wasn't there when `state` was constructed.
  # Objects whose name starts with "." are not deleted.

  rm(list = setdiff(ls(.GlobalEnv), state$globals),
     envir = .GlobalEnv)
}

opts_chunk$set(
  echo = TRUE,
  fig.path = "static/img/figs/",
  dev="ragg_png",
  message = FALSE,
  dpi = 150,
  comment = NA)

knit_hooks$set(link_preview = function(before, options, envir) {
  if (!before && is_truthy(options$link_preview)){
    return(process_link_preview_options(options))
  }
})

if (!exists(".initial_state")) {
  .initial_state <- currentState()
}
```
## Laboratory Tables







<!--chapter:end:04-03-lab.Rmd-->

---
output: html_document
editor_options: 
  chunk_output_type: console
---
```{r include=FALSE, cache=FALSE}
library(knitr)
library(magrittr)
library(ragg)
library(random.cdisc.data)

is_doconvable <- require("doconv") && locatexec::exec_available("word")
is_webshotable <- require("webshot2")

is_truthy <- function(x) {
  if (inherits(x, "try-error"))
    return(FALSE)
  if (!is.atomic(x))
    return(TRUE)
  if (is.null(x))
    return(FALSE)
  if (length(x) == 0)
    return(FALSE)
  if (all(is.na(x)))
    return(FALSE)
  if (is.character(x) && !any(nzchar(stats::na.omit(x))))
    return(FALSE)
  if (is.logical(x) && !any(stats::na.omit(x)))
    return(FALSE)
  return(TRUE)
}

process_link_preview_options  <- function(options){
  if(!is_truthy(options$link_preview)) return("")
  if(!options$link_preview) return("")
  if(!is_truthy(options$path_to_doc)) return("")

  png_file <- gsub("\\.(pptx|docx|pdf|html)$", ".png", options$path_to_doc)
  width <- options$width
  if(is.null(width)) {
    if(!grepl("\\.pptx$", options$path_to_doc)) width <- 650
    else width <- 750
  }

  if(!file.exists(png_file) && is_doconvable && grepl("\\.docx$", options$path_to_doc)) {
    doconv::to_miniature(filename = options$path_to_doc, fileout = png_file, width = width, row = options$row)
  } else if(!file.exists(png_file) && is_doconvable && grepl("\\.pdf$", options$path_to_doc)) {
    doconv::to_miniature(filename = options$path_to_doc, fileout = png_file, width = width, row = options$row)
  } else if(!file.exists(png_file) && is_doconvable && grepl("\\.pptx$", options$path_to_doc)) {
    doconv::to_miniature(filename = options$path_to_doc, fileout = png_file, width = width, row = options$row)
  } else if (!file.exists(png_file) && is_webshotable) {
    webshot2::webshot(options$path_to_doc, vwidth = width,
      file = png_file, cliprect = "viewport")
  }

  img_code <- sprintf("![](%s)\n\n", png_file)
  lnk_code <- sprintf("::: {.office-download-link}\n\n[%s](%s)\n\n:::\n\n", options$path_to_doc, options$path_to_doc)
  return(paste0(img_code, lnk_code))
}

currentState <- function() {
  list(globals = ls(.GlobalEnv),
       search = search())
}

resetSession <- function(state = .initial_state) {
  # Clean up the search list
  for (n in setdiff(search(), state$search)) {
    detach(n, character.only = TRUE)
  }

  # Clean up the global environment by deleting everything
  # that wasn't there when `state` was constructed.
  # Objects whose name starts with "." are not deleted.

  rm(list = setdiff(ls(.GlobalEnv), state$globals),
     envir = .GlobalEnv)
}

opts_chunk$set(
  echo = TRUE,
  fig.path = "static/img/figs/",
  dev="ragg_png",
  message = FALSE,
  dpi = 150,
  comment = NA)

knit_hooks$set(link_preview = function(before, options, envir) {
  if (!before && is_truthy(options$link_preview)){
    return(process_link_preview_options(options))
  }
})

if (!exists(".initial_state")) {
  .initial_state <- currentState()
}
```

## Time to Event Analysis Tables

### Data and models used throughout

```{r, comment=NA}
resetSession()
library(dplyr)
library(tidyr)
library(stringr)
library(purrr)
library(survival)

data("cadaette", package = "random.cdisc.data")
head(cadaette)

adtte <- cadaette %>% 
    dplyr::filter(PARAMCD == "AETTE2", SAFFL == "Y")

```

Cox Proportional Hazard fit:
```{r}
cph <- coxph(Surv(AVAL, CNSR==0) ~ TRT01A + STRATA1, ties = "exact", data = adtte)
```

Kaplan-Meier Model

```{r}
surv_tbl <- as.data.frame(summary(survfit(Surv(AVAL, CNSR==0) ~ TRT01A,
                                          data = adtte, conf.type = "log-log"))$table) %>%
    dplyr::mutate(TRT01A = factor(str_remove(row.names(.), "TRT01A="),
                                  levels = levels(adtte$TRT01A)),
                  ind = FALSE)
.kmState <- currentState()
```

### rtables

```{r, comment=NA}
resetSession(.kmState)
library(rtables)

cnsr_counter <- function(df, .var, .N_col) {
    x <- df[!duplicated(df$USUBJID), .var]
    x <- x[x != "__none__"]
    lapply(table(x), function(xi) rcell(xi*c(1, 1/.N_col), format = "xx (xx.xx%)"))
}
            
a_count_subjs <- function(x, .N_col) {
    in_rows("Subjects with Adverse Events n (%)" = rcell(length(unique(x)) * c(1, 1 / .N_col),
                                                                           format = "xx (xx.xx%)"))
}

a_cph <- function(df, .var, .in_ref_col, .ref_full, full_cox_fit) {
    if(.in_ref_col) {
        ret <- replicate(3, list(rcell(NULL)))
    } else {
        curtrt <- df[[.var]][1]
        coefs <- coef(full_cox_fit)
        sel_pos <- grep(curtrt, names(coefs), fixed = TRUE)
        hrval <- exp(coefs[sel_pos])
        hrvalret <- rcell(hrval, format = "xx.x")
        sdf <- survdiff(Surv(AVAL, CNSR==0) ~ TRT01A + STRATA1,
                        data = rbind(df, .ref_full))
        pval <- (1-pchisq(sdf$chisq, length(sdf$n)-1))/2
        ci_val <- exp(unlist(confint(full_cox_fit)[sel_pos,]))
        ret <- list(rcell(hrval, format = "xx.x"),
                    rcell(ci_val, format = "(xx.x, xx.x)"),
                    rcell(pval, format = "x.xxxx | (<0.0001)"))
    }
    in_rows(.list = ret, .names = c("Hazard ratio",
                                    "95% confidence interval",
                                    "p-value (one-sided stratified log rank)"))
}

a_tte <- function(df, .var,  kp_table) {
    ind <- grep(df[[.var]][1], row.names(kp_table), fixed = TRUE)
    minmax <- range(df[["AVAL"]])

    mm_val_str <- format_value(minmax, format = "xx.x, xx.x")
    rowfn <- list()
    if(all(df$CNSR[df$AVAL == minmax[2]])) {
        mm_val_str <- paste0(mm_val_str, "*")
        rowfn <- "* indicates censoring"
    }
    in_rows(Median = kp_table[ind, "median", drop = TRUE],
            "95% confidence interval" = unlist(kp_table[ind, c("0.95LCL", "0.95UCL")]),
            "Min Max" = mm_val_str,
            .formats = c("xx.xx",
                         "xx.xx - xx.xx",
                         "xx"), .row_footnotes = list(NULL, NULL, rowfn))
}
            

adtte2 <- adtte %>%
    mutate(CNSDTDSC = ifelse(CNSDTDSC == "", "__none__", CNSDTDSC))


lyt <- basic_table(show_colcounts = TRUE,
                   title = "x.x: Safety Data",
                   subtitles = c("x.x.x: Time to First Serious Adverse Event",
                                 "Table x.x.x.x: Safety Endpoint - Safety Analysis Set"),
                   main_footer = c("Serious adverse events are defines as (...). All p-values are exploratory.",
                                   "Hazard ratios are from a stratified Cox model of serious adverse event hazard rate,",
                                   "with terms for treatment groups and strata1. Ties were handled using the exact",
                                   "method. Hazard ratios of Placebo Combination over Drug X are presented, an",
                                   "HR < 1 denotes improvement compared to Drug X."),
                   prov_footer = "Source: ADTTE DDMMYYYY hh:mm; Listing x.xx; SDTM package: DDMMYYYY") %>%
    ## column faceting
    split_cols_by("ARM", ref_group = "A: Drug X") %>%
    ## overall count
    analyze("USUBJID", a_count_subjs, show_labels = "hidden") %>%
    ## Censored Subjects Summary
    analyze("CNSDTDSC", cnsr_counter, var_labels = "Censored Subjects", show_labels = "visible") %>%
    ## CPH analysis
    analyze("ARM", a_cph, extra_args = list(full_cox_fit = cph), show_labels = "hidden") %>%
    ## Time-to-event analysis
    analyze("ARM", a_tte, var_labels = "Time to first adverse event", show_labels = "visible",
            extra_args = list(kp_table = surv_tbl),
            table_names = "kapmeier")

tbl_tte <- build_table(lyt, adtte2)

fnotes_at_path(tbl_tte, c("ma_USUBJID_CNSDTDSC_ARM_kapmeier", "kapmeier")) <- "Product-limit (Kaplan-Meier) estimates."
tbl_tte

```
    
            
    
### Cell Value Derivation for gt of Time to Event Analysis


Our standard TTE table consists of (a derivation of) four main parts:

1. Descriptive stats including the number of subjects with an event, number of subjects censored and censoring reasons
2. Hazard ratio with corresponding 95% CI from a (stratified) Cox model and a p-value from a stratified log rank test
3. Median time to event Kaplan-Meier analysis
4. Number of patients at risk at specified visits from Kaplan-Meier analysis (omitted here).

```{r descr_stats}
resetSession(.kmState)
library(gt)
### Subject Count with events

## surv_tbl calculated above


subj_count <- surv_tbl %>%
  dplyr::mutate(pct = sprintf("%i (%5.1f)", events, 100*events/records),
                label = "Number of subjects with serious adverse event, n (%)") %>%
  dplyr::select(label, TRT01A, pct) %>%
  tidyr::pivot_wider(id_cols = label, names_from = TRT01A, values_from = pct) %>%
  dplyr::mutate(ind = FALSE)

# Number of censored subjects

cnsrd_subj_full <- surv_tbl %>% 
  dplyr::mutate(pct = sprintf("%i (%4.1f)", records-events, 100*(records-events)/records),
                CNSDTDSC = "Number of censored subjects, n (%)") %>% 
  dplyr::select(CNSDTDSC, TRT01A, pct)
  
cnsrd_subj <- adtte %>% 
  dplyr::group_by(TRT01A) %>%
  dplyr::mutate(CNSR = CNSR/n()) %>%
  dplyr::ungroup() %>%
  dplyr::filter(CNSR != 0) %>%
  dplyr::group_by(TRT01A, CNSDTDSC) %>%
  dplyr::summarise(pct = sprintf("%i (%4.1f)", sum(CNSR != 0), 100*sum(CNSR))) %>%
  dplyr::ungroup() %>%
  dplyr::bind_rows(cnsrd_subj_full, .) %>% 
  tidyr::pivot_wider(id_cols = CNSDTDSC, names_from = TRT01A, values_from = pct) %>%
  dplyr::rename(label = CNSDTDSC) %>%
  dplyr::mutate(ind = label != "Number of censored subjects, n (%)") %>% 
  dplyr::arrange(ind)
```

```{r cox_mod}
## cph calculated above
hr <- exp(coef(cph))
ci_hr <- exp(confint(cph))

# Hazard ratio and 95% CI

df_hr <- cbind(ci_hr, hr) %>%
  as.data.frame() %>%
  dplyr::filter(grepl("TRT01A", row.names(.))) %>% 
  dplyr::mutate(TRT01A = factor(str_remove(row.names(.), "TRT01A")),
                ci = sprintf("[%4.1f, %4.1f]", round(!!sym("2.5 %"), 1), round(!!sym("97.5 %"), 1))) %>%
  dplyr::select(TRT01A, hr, ci)

# Log rank p-value

log_rank_test <- purrr::map_df(.x = list(c("A: Drug X", "B: Placebo"),
                                         c("A: Drug X", "C: Combination")),
                               .f = ~{sdf <- survdiff(Surv(AVAL, CNSR==0) ~ TRT01A + STRATA1,
                                                      data = adtte %>% dplyr::filter(TRT01A %in% .x));
                               data.frame(TRT01A = .x[2],
                                          pval = (1-pchisq(sdf$chisq, length(sdf$n)-1))/2)})

df_hr_comp <- merge(df_hr, log_rank_test, by = "TRT01A") %>%
  dplyr::mutate(hr = sprintf("%4.1f", round(hr, 1)),
                pval = ifelse(pval < 0.0001, "<0.0001", sprintf("%6.4f", round(pval, 4)))) %>%
  tidyr::pivot_longer(cols = c(hr, ci, pval), names_to = "label", values_to = "val") %>%
  tidyr::pivot_wider(names_from = TRT01A, values_from = "val") %>%
  dplyr::mutate(label = dplyr::recode(label,
                                      "hr" = "Hazard ratio",
                                      "ci" = "95% confidence interval",
                                      "pval" = "p-value (one-sided stratified log rank)"),
                ind = FALSE)
```

```{r km}
median_survtime <- surv_tbl %>%
  dplyr::mutate(ci = sprintf("[%4.2f, %4.2f]", !!sym("0.95LCL"), !!sym("0.95UCL")),
                median = sprintf("%4.2f", median),
                id = "") %>%
  dplyr::select(TRT01A, id, median, ci) %>%
  tidyr::pivot_longer(cols = c(id, median, ci), names_to = "label", values_to = "val") %>%
  tidyr::pivot_wider(names_from = TRT01A, values_from = val) %>%
  dplyr::mutate(ind = label != "id",
                label = dplyr::recode(label, "median" = "Median (years)",
                                      "ci" = "95% confidence interval",
                                      "id" = "Time to first serious adverse event (a)"))

min_max <- adtte %>%
  dplyr::filter(!(AVAL == 0 & CNSR == 1)) %>% 
  dplyr::group_by(TRT01A) %>%
  dplyr::mutate(max_cnsr = !is.na(AVAL) & AVAL == max(AVAL, na.rm = TRUE) & CNSR == 1) %>%
  dplyr::summarise(min_max = sprintf("%4.2f, %4.2f%s",
                                     min(AVAL, na.rm = TRUE),
                                     max(AVAL, na.rm = TRUE),
                                     ifelse(sum(max_cnsr) > 0, "*", ""))) %>%
  dplyr::ungroup() %>%
  tidyr::pivot_wider(names_from = TRT01A, values_from = min_max) %>%
  dplyr::mutate(label = "Min, Max (b)",
                ind = TRUE)

model_sum <- dplyr::bind_rows(subj_count, cnsrd_subj, df_hr_comp, median_survtime, min_max)
```



### gt

```{r}
header_n <- adtte %>%
  dplyr::group_by(TRT01A) %>%
  dplyr::summarise(TRT = sprintf("%s<br>N=%i (100%%)", unique(TRT01A), n())) %>%
  dplyr::ungroup()


### Begin table creation

gt(model_sum) %>%
  cols_hide(ind) %>%
  tab_header(
    title = "x.x: Safety Data",
    subtitle = html("x.x.x: Time to First Serious Adverse Event<br>Table x.x.x.x: Safety Endpoint - Safety Analysis Set"),
    preheader = c("Protocol: XXXXX", "Cutoff date: DDMMYYYY")
  ) %>%
  tab_source_note("Source: ADTTE DDMMYYYY hh:mm; Listing x.xx; SDTM package: DDMMYYYY") %>%
  opt_align_table_header(align = "left") %>%
  cols_align(align = c("center"),
             columns = c("A: Drug X", "B: Placebo", "C: Combination")) %>%
  cols_align(align = "left",
             columns = "label") %>%
  tab_style(style = cell_text(indent = pct(5)),
            locations = cells_body(columns = 1,
                                   rows = ind == TRUE)) %>%
  sub_missing(columns = everything(), missing_text = "") %>%
  cols_label("label" = "",
             "A: Drug X" = html(header_n$TRT[1]),
             "B: Placebo" = html(header_n$TRT[2]),
             "C: Combination" = html(header_n$TRT[3])) %>%
  tab_footnote(footnote = html("Serious adverse events are defines as (...). All p-values are exploratory.<br>(a) Product-limit (Kaplan-Meier) estimates. <br>(b) Minimum and maximum of event times. * Denotes censoring.<br>Hazard ratios are from a stratified Cox model of serious adverse event hazard rate, with terms for treatment groups and strata1. Ties were handled using the exact method. Hazard ratios of Placebo/ Combination over Drug X are presented, a HR < 1 denotes improvement compared to Drug X.")) %>%
  tab_options(
    table.font.names = "Courier new",
    table.font.size = 9,
    page.orientation = "landscape",
    page.numbering = TRUE,
    page.header.use_tbl_headings = TRUE,
    page.footer.use_tbl_notes = TRUE)
```



### flextable


```{r}
resetSession(.kmState)
ARM_COUNTS <- .ARM_COUNTS # Restore from previous section

library(flextable)
library(tidyverse)

# labels and notes ----
# named vectors that will be used later as 
# labels for the table.
description_labels <- c(SAE = "Number of subjects with serious adverse event", CENSOR_EVENTS = "Number of censored subjects",
  HAZARD_RATIO = "Hazard ratio", TTF_SAE = "Time to first adverse event")
subdescription_labels <- c(subdescription = "",
  ALL = "Censored Subjects", EST = "Estimate", CONFINT = "95% confidence interval",
  PVALUE = "one-sided stratified log rank p-value",
  MEDIAN = "Median", RANGE = "Min Max")
labels <- c(description_labels, subdescription_labels)

additional_notes <- c(
  "Serious adverse events are defines as (...). All p-values are exploratory.", 
  paste("Hazard ratios are from a stratified Cox model", 
        "of serious adverse event hazard rate, with terms for treatment groups and strata1.", 
        "Ties were handled using the exact method. Hazard ratios of Placebo/ Combination over", 
        "Drug X are presented, a HR < 1 denotes improvement compared to Drug X."))
titles <- c(
  "x.x: Safety Data",
  "x.x.x: Time to First Serious Adverse Event",
  "Table x.x.x.x: Safety Endpoint - Safety Analysis Set")

# Data need to be prepared in a single data.frame, 
# a function is written to make the code simplier to organize.
#' @noRd
#' @description create a data.frame made of 
#' several sub data.frame, each for a specific 
#' calculation. Final result has two specific columns 
#' 'description' and 'subdescription' that will 
#' contain various labels or group labels.
prepare_tte_df <- function(adtte, cph, surv_tbl) {
  ## Number of subjects with serious adverse event ----
  subj_count <- surv_tbl |>
    select(TRT01A, n = events, records) |>
    mutate(pct = n / records, description = "SAE", subdescription = "ALL")

  ## Number of censored subjects ----
  subj_censored <- subj_count |>
    mutate(
      n = records - n, pct = 1 - pct, description = "CENSOR_EVENTS",
      subdescription = "ALL"
    )

  ## Number of censored subjects - detail per CNSDTDSC ----
  subj_censored_detail <- adtte |>
    filter(CNSR > 0) |>
    count(TRT01A, CNSDTDSC) |>
    left_join(subj_count |> select(TRT01A, records), by = "TRT01A") |>
    mutate(pct = n / records, description = "CENSOR_EVENTS") |>
    rename(subdescription = "CNSDTDSC")

  ## Hazard ratio and 95% CI ----
  coefs_hr <- cbind(exp(confint(cph)), y = exp(coef(cph))) |> as.data.frame() |>
    rownames_to_column(var = "TRT01A") |>
    filter(grepl("TRT01A", TRT01A)) |>
    mutate(TRT01A = str_replace(TRT01A, "TRT01A", ""))

  hr_dat <- bind_rows(
    select(coefs_hr, TRT01A, LCL = `2.5 %`, UCL = `97.5 %`) |>
      mutate(description = "HAZARD_RATIO", subdescription = "CONFINT"),
    select(coefs_hr, TRT01A, y) |>
      mutate(description = "HAZARD_RATIO", subdescription = "EST")
  )

  ## p-value (one-sided stratified log rank)	 ----
  pval_dat <- purrr::map_df(
    .x = list(c("A: Drug X", "B: Placebo"), c("A: Drug X", "C: Combination")),
    .f = ~ {
      sdf <- survdiff(Surv(AVAL, CNSR == 0) ~ TRT01A + STRATA1, data = adtte |> 
                        dplyr::filter(TRT01A %in% .x))
      data.frame(TRT01A = .x[2], description = "HAZARD_RATIO", subdescription = "PVALUE",
        y = (1 - pchisq(sdf$chisq, length(sdf$n) - 1)) / 2)
    }
  )

  ## Time to first serious adverse event ----
  tfe_dat <- bind_rows(
    surv_tbl |>
      select(TRT01A, LCL = `0.95LCL`, UCL = `0.95UCL`) |>
      mutate(description = "TTF_SAE", subdescription = "CONFINT"),
    surv_tbl |>
      select(TRT01A, y = median) |>
      mutate(description = "TTF_SAE", subdescription = "MEDIAN"),
    adtte |>
      filter(!(AVAL == 0 & CNSR == 1)) |>
      group_by(TRT01A) |>
      mutate(max_cnsr = !is.na(AVAL) & AVAL == max(AVAL, na.rm = TRUE) & CNSR == 1) |>
      summarise(
        min = min(AVAL, na.rm = TRUE),
        max = max(AVAL, na.rm = TRUE),
        is_censored = sum(max_cnsr) > 0,
        description = "TTF_SAE", subdescription = "RANGE"
      )
  )
  
  cnsdtdsc_levels <- unique(adtte$CNSDTDSC) |> sort() |> setdiff("")

  dat <- bind_rows(subj_count, subj_censored, subj_censored_detail, hr_dat, pval_dat, tfe_dat) |> 
    as_tibble() |>
    ## factor for easy ordering ----
    mutate(
      description = factor(description, levels = c("SAE", "CENSOR_EVENTS", "HAZARD_RATIO", "TTF_SAE")),
      subdescription = factor(subdescription,
      levels = c("ALL", cnsdtdsc_levels, "NUSUBJID", "MEDIAN", "EST", "CONFINT", "PVALUE", "RANGE")))

  dat
}
dat <- prepare_tte_df(adtte, cph, surv_tbl)

# Now data.frame is ready to be formatted with `fmt_time_to_event()`. 
# The function handle each special cases to be covered so that 
# the four main parts are formatted as expected.

library(glue)
library(dplyr)
# format fun ----
fmt_time_to_event <- function(description, subdescription, y, cts, pcts, LCL, UCL, min, max, is_censored) {
  case_when(
    !is.na(cts) & !is.na(pcts) ~ glue('{sprintf("%.0f", cts)} ({sprintf("%.02f", pcts*100)}%)'),
    !is.na(y) & !subdescription %in% "PVALUE" ~ glue('{sprintf("%.02f", y)}'),
    !is.na(y) & subdescription %in% "PVALUE" ~ glue("{scales::label_pvalue()(y)}"),
    !is.na(LCL) & !is.na(UCL) ~ glue('[{sprintf("%.02f", LCL)}, {sprintf("%.02f", UCL)}]'),
    !is.na(LCL) & !is.na(UCL) ~ glue('[{sprintf("%.02f", LCL)}, {sprintf("%.02f", UCL)}]'),
    !is.na(min) & !is.na(max) & is_censored ~ glue('{sprintf("%.02f", min)}, {sprintf("%.02f", max)}*'),
    !is.na(min) & !is.na(max) & !is_censored ~ glue('{sprintf("%.02f", min)}, {sprintf("%.02f", max)}'),
    TRUE ~ ""
  )
}

# use `tabulator()` and `as_flextable()` together to create the table. 

tab <- tabulator(dat,
  rows = c("description", "subdescription"), columns = "TRT01A",
  content_cell = as_paragraph(
    fmt_time_to_event(
      description = description, subdescription = subdescription,
      y = y, cts = n, pcts = pct, LCL = LCL, UCL = UCL,
      min = min, max = max, is_censored = is_censored))
)
ft <- as_flextable(x = tab, spread_first_col = TRUE, separate_with = "description", sep_w = 0) |>
  # footnotes
  footnote(
    j = 1, i = ~ description %in% c("CENSOR_EVENTS", "SAE"),
    ref_symbols = " (1)", value = as_paragraph(" Number of subjects (% of subjects)")
  ) |>
  footnote(
    j = 1, i = ~ description %in% "TTF_SAE" & is.na(subdescription), ref_symbols = " (2)",
    value = as_paragraph(" Product-limit (Kaplan-Meier) estimates.")
  ) |>
  footnote(
    j = 1, i = ~ subdescription %in% "RANGE", ref_symbols = " (3)",
    value = as_paragraph(" * indicates censoring")
  ) |>
  add_footer_lines(values = additional_notes) |>
  # labels
  labelizor(j = "subdescription", labels = labels, part = "all") |>
  # indentation
  prepend_chunks(i = ~ is.na(description), j = "subdescription", as_chunk("\t")) |>
  align(i = ~ !is.na(description), align = "left") |>
  autofit() |>
  add_header_lines(values = titles) |>
  hline_top(part = "header", border = fp_border_default(width = 0)) |>
  hline(part = "header", i = 1:2, border = fp_border_default(width = 0))

for (ARM_COD in names(ARM_COUNTS)) {
  ft <- append_chunks(x = ft, part = "header", i = 4,
    j = tabulator_colnames(tab, columns = "content_cell", TRT01A %in% !!ARM_COD),
    as_chunk(ARM_COUNTS[ARM_COD], formatter = fmt_header_n))
}
ft
```

### tables

```{r}
resetSession(.kmState)

library(tables)
table_options(doCSS = TRUE)

ex_adae <- formatters::ex_adae

subject_counts <- table(adsl$ARM)

countpercentid <- function(num, ARM) {
  n <- length(unique(num))
  sprintf("%d (%.2f%%)", 
          length(unique(num)), 
          100*n/subject_counts[ARM[1]])
}

valuepercent <- function(x, ARM) {
  sprintf("%d (%.2f%%)", x, 100*x/subject_counts[ARM] )
}

blanks <- function(x) ""

count <- function(x) sprintf("(N=%d)", length(x))

hazardratio <- function(ARM) {
  entry <- paste0("TRT01A", ARM)
  coef <- coef(cph)
  if (entry %in% names(coef)) sprintf("%.1f", exp(coef[entry]))
  else ""
}

hazardratioconfint <- function(ARM) {
  entry <- paste0("TRT01A", ARM)
  confint <- confint(cph)
  if (entry %in% rownames(confint)) {
    confint <- as.numeric(confint[entry,])
    sprintf("(%.1f, %.1f)", exp(confint[1]), exp(confint[2]))
  } else ""
}

hazardpvalue <- function(ARM) {
  if (ARM == "A: Drug X") ""
  else {
    twogroups <- c("A: Drug X", ARM)
    sdf <- survdiff(Surv(AVAL, CNSR==0) ~ TRT01A + STRATA1,
                   data = adtte, subset = TRT01A %in% twogroups)
    pval <- (1-pchisq(sdf$chisq, length(sdf$n)-1))/2
    sprintf("%.4f", pval)
  }
}

Median <- function(ARM) {
  vals <- subset(surv_tbl, TRT01A == ARM)
  sprintf("%.2f", vals$median)
}

minmaxevent <- function(ARM) {
  vals <- subset(adtte, TRT01A == ARM)
  sprintf("%.2f, %.2f", min(vals$AVAL), max(vals$AVAL))
}

eventCI <- function(ARM) {
  vals <- subset(surv_tbl, TRT01A == ARM)
  sprintf("[%.2f, %.2f]", vals$`0.95LCL`, vals$`0.95UCL`)
}

heading <- tabular(Heading("")*1*Heading("")*count ~ 
                   Heading()*ARM, 
                   data = adsl)

part1 <- tabular( Heading("Subjects with serious adverse events")*1*Heading("")*
                    events*Heading()*
                    valuepercent*Arguments(ARM = TRT01A) ~ 
                  Heading()*TRT01A, 
                  data = surv_tbl )

part2 <- tabular( Heading("Number of censored subjects")*1*Factor(CNSDTDSC, "")*
                Heading()*countpercentid*Arguments(ARM = TRT01A)*
                    Heading()*USUBJID ~
                  Heading()*TRT01A, 
                  data = subset(adtte, nchar(CNSDTDSC) > 0))

part3 <- tabular( ( Heading("Hazard ratio")*1*Heading("")*hazardratio +
                    Heading("95% confidence interval")*1*Heading("")*hazardratioconfint +
                    Heading("p-value (one-sided stratified log rank)")*1*Heading("")*hazardpvalue +
                    Heading("Time to first serious adverse event")*1*(
                      Heading("Median (years)")*Median +
                      Heading("95% confidence interval")*eventCI +
                      Heading("Min, Max")*minmaxevent))*
                    Heading()*as.character(TRT01A)  ~
                  Heading()*TRT01A,
                  data = surv_tbl)

useGroupLabels(rbind(heading, part1, part2, part3),
               indent = "&emsp;")
```

<!--chapter:end:04-04-kaplan-meier.Rmd-->

---
output: html_document
editor_options: 
  chunk_output_type: console
---
```{r include=FALSE, cache=FALSE}
library(knitr)
library(magrittr)
library(ragg)
library(random.cdisc.data)

is_doconvable <- require("doconv") && locatexec::exec_available("word")
is_webshotable <- require("webshot2")

is_truthy <- function(x) {
  if (inherits(x, "try-error"))
    return(FALSE)
  if (!is.atomic(x))
    return(TRUE)
  if (is.null(x))
    return(FALSE)
  if (length(x) == 0)
    return(FALSE)
  if (all(is.na(x)))
    return(FALSE)
  if (is.character(x) && !any(nzchar(stats::na.omit(x))))
    return(FALSE)
  if (is.logical(x) && !any(stats::na.omit(x)))
    return(FALSE)
  return(TRUE)
}

process_link_preview_options  <- function(options){
  if(!is_truthy(options$link_preview)) return("")
  if(!options$link_preview) return("")
  if(!is_truthy(options$path_to_doc)) return("")

  png_file <- gsub("\\.(pptx|docx|pdf|html)$", ".png", options$path_to_doc)
  width <- options$width
  if(is.null(width)) {
    if(!grepl("\\.pptx$", options$path_to_doc)) width <- 650
    else width <- 750
  }

  if(!file.exists(png_file) && is_doconvable && grepl("\\.docx$", options$path_to_doc)) {
    doconv::to_miniature(filename = options$path_to_doc, fileout = png_file, width = width, row = options$row)
  } else if(!file.exists(png_file) && is_doconvable && grepl("\\.pdf$", options$path_to_doc)) {
    doconv::to_miniature(filename = options$path_to_doc, fileout = png_file, width = width, row = options$row)
  } else if(!file.exists(png_file) && is_doconvable && grepl("\\.pptx$", options$path_to_doc)) {
    doconv::to_miniature(filename = options$path_to_doc, fileout = png_file, width = width, row = options$row)
  } else if (!file.exists(png_file) && is_webshotable) {
    webshot2::webshot(options$path_to_doc, vwidth = width,
      file = png_file, cliprect = "viewport")
  }

  img_code <- sprintf("![](%s)\n\n", png_file)
  lnk_code <- sprintf("::: {.office-download-link}\n\n[%s](%s)\n\n:::\n\n", options$path_to_doc, options$path_to_doc)
  return(paste0(img_code, lnk_code))
}

currentState <- function() {
  list(globals = ls(.GlobalEnv),
       search = search())
}

resetSession <- function(state = .initial_state) {
  # Clean up the search list
  for (n in setdiff(search(), state$search)) {
    detach(n, character.only = TRUE)
  }

  # Clean up the global environment by deleting everything
  # that wasn't there when `state` was constructed.
  # Objects whose name starts with "." are not deleted.

  rm(list = setdiff(ls(.GlobalEnv), state$globals),
     envir = .GlobalEnv)
}

opts_chunk$set(
  echo = TRUE,
  fig.path = "static/img/figs/",
  dev="ragg_png",
  message = FALSE,
  dpi = 150,
  comment = NA)

knit_hooks$set(link_preview = function(before, options, envir) {
  if (!before && is_truthy(options$link_preview)){
    return(process_link_preview_options(options))
  }
})

if (!exists(".initial_state")) {
  .initial_state <- currentState()
}
```
## Concomitant Medications

### rtables

```{r}
resetSession()

library(rtables)
data("cadcm", package = "random.cdisc.data")
data("cadsl", package = "random.cdisc.data")

one_count_pct_gen <- function(label = NULL) {
    function(x, .N_col) {
       ret <- rcell(length(unique(x)) * c(1, 1/.N_col),
                    format = "xx (xx.x%)")
       if(!is.null(label))
           obj_label(ret) <- label
       ret
    }
}

lyt <- basic_table(title = "Conmed Example",
                   subtitles = "Uses the adcm dataset from random.cdisc.data",
                   show_colcounts = TRUE) %>%
    split_cols_by("ARM") %>%
    analyze("USUBJID", afun = one_count_pct_gen("At Least One Concomittant Med")) %>%
    split_rows_by("CMCLAS", split_fun = trim_levels_in_group("CMTRT")) %>%
    analyze("CMTRT", afun = function(df, .N_col) {
        cmtrtvec <- df$CMTRT
        spl_usubj <- split(df$USUBJID, cmtrtvec)
        fn <- one_count_pct_gen()
        cells <- lapply(spl_usubj, fn, .N_col = .N_col)
        names(cells) <- names(spl_usubj)
        in_rows(.list = cells)
    })

build_table(lyt, cadcm, alt_counts_df = cadsl)
```

### gt

```{r, comment=NA}
resetSession()

library(dplyr)
library(tidyr)
library(gt)

data("cadcm", package = "random.cdisc.data")
data("cadsl", package = "random.cdisc.data")


cmdecod_levels <- c("Number of sujects with any concomitant medication", levels(cadcm$CMDECOD))
cmclas_levels <- c(NA, levels(cadcm$CMCLAS))

adcm <- cadcm |> 
  select(CMDECOD, CMCLAS, TRT01A) |> 
  mutate(
    CMDECOD = factor(CMDECOD, levels = cmdecod_levels),
    CMCLAS = factor(CMCLAS, levels = cmclas_levels)
    )

ct_cm <- dplyr::group_by(cadcm, TRT01A) |> 
  dplyr::summarize(n = dplyr::n_distinct(USUBJID)) |> 
  dplyr::left_join(count(cadsl, TRT01A, name = "nall"), by = "TRT01A") |> 
  dplyr::mutate(pct = n / nall, nall = NULL,
                CMDECOD = factor("Number of sujects with any concomitant medication", levels = cmdecod_levels))

ct_adcm <- dplyr::group_by(cadcm, TRT01A, CMCLAS, CMDECOD) |> 
  dplyr::summarize(n = dplyr::n_distinct(USUBJID)) |> 
  dplyr::left_join(count(cadsl, TRT01A, name = "nall"), by = "TRT01A") |> 
  dplyr::mutate(pct = n / nall, nall = NULL)

gt_adcm <- dplyr::bind_rows(ct_cm, ct_adcm) |>  
  tidyr::pivot_wider(id_cols = c(CMCLAS, CMDECOD), names_from = TRT01A, values_from = c(n, pct)) 

## don't print it yet, uncomment when its ready
##gt_adcm %>% gt()

trt_n <- cadsl |> 
  dplyr::filter(SAFFL == "Y") |> 
  dplyr::group_by(TRT01A) |> 
  dplyr::summarize(n = sprintf("%s  \nN=%i (100%%)", unique(TRT01A), dplyr::n())) |> 
  dplyr::ungroup()

tab_n <- dplyr::pull(trt_n, n) |> 
  as.list()
names(tab_n) <- paste("n", dplyr::pull(trt_n, TRT01A), sep = "_")


gt_adcm |> 
  gt(rowname_col = "CMDECOD") |> 
  tab_header(
    title = "Conmed Example",
    subtitle = md("Uses the *adcm* dataset from **random.cdisc.data**")
  ) |> 
  opt_align_table_header(align = "left") |> 
  fmt_percent(columns = dplyr::starts_with("pct_"), decimals = 1) |> 
  cols_merge_n_pct(col_n = "n_A: Drug X", col_pct = "pct_A: Drug X") |> 
  cols_merge_n_pct(col_n = "n_B: Placebo", col_pct = "pct_B: Placebo") |> 
  cols_merge_n_pct(col_n = "n_C: Combination", col_pct = "pct_C: Combination") |> 
  tab_row_group(
    label = "medcl A",
    rows = CMCLAS == "medcl A"
  ) |>
  tab_row_group(
    label = "medcl B",
    rows = CMCLAS == "medcl B"
  ) |>
  tab_row_group(
    label = "medcl C",
    rows = CMCLAS == "medcl C"
  ) |>
  row_group_order(
    groups = c(NA, paste("medcl", LETTERS[1:2])) 
  ) |> 
  cols_hide(CMCLAS) |> 
  cols_label(
    `n_A: Drug X` = md(tab_n[[1]]),
    `n_B: Placebo` = md(tab_n[[2]]),
    `n_C: Combination` = md(tab_n[[3]])
  ) |> 
  cols_width(
    1 ~ px(500),
    everything() ~ px(150)
  ) |> 
  cols_align(
    align = "center",
    columns = everything()
  ) |> 
  cols_align(
    align = "left",
    columns = 1
  ) 

```

### flextable

```{r}
resetSession()

library(flextable)
library(dplyr)
library(forcats)

data("cadcm", package = "random.cdisc.data")
data("cadsl", package = "random.cdisc.data")


cmdecod_levels <- c("N_CM", levels(cadcm$CMDECOD))
cmclas_levels <- c("N_CM", levels(cadcm$CMCLAS))

adcm <- cadcm |> 
  select(CMDECOD, CMCLAS, TRT01A) |> 
  mutate(
    CMDECOD = factor(CMDECOD, levels = cmdecod_levels),
    CMCLAS = factor(CMCLAS, levels = cmclas_levels)
    )

trt_count <- group_by(cadsl, TRT01A) |> 
  summarise(n = n())
trt_count <- setNames(trt_count$n, trt_count$TRT01A)

ct_cm <- group_by(cadcm, TRT01A) |> 
  summarise(n = n_distinct(USUBJID)) |> 
  left_join(count(cadsl, TRT01A, name = "nall"), by = "TRT01A") |> 
  mutate(pct = n / nall, nall = NULL,
         CMCLAS = factor("N_CM", levels = cmclas_levels), 
         CMDECOD = factor("N_CM", levels = cmdecod_levels))

ct_adcm <- group_by(cadcm, TRT01A, CMCLAS, CMDECOD) |> 
  summarize(n = n_distinct(USUBJID)) |> 
  ungroup() |> 
  left_join(count(cadsl, TRT01A, name = "nall"), by = "TRT01A") |> 
  mutate(pct = n / nall, nall = NULL)

dat <- bind_rows(ct_cm, ct_adcm)

tab <- tabulator(
  dat, rows = c("CMCLAS", "CMDECOD"), columns = "TRT01A",
  cts = as_paragraph(fmt_n_percent(n, pct)))

ft <- as_flextable(tab, spread_first_col = TRUE) |> 
  prepend_chunks(
    i = ~ is.na(CMCLAS) & seq_along(CMCLAS) > 1, j = 1, 
    as_chunk("\t")
  )

for(TRT01A_COD in names(trt_count)){
  ft <- append_chunks(
    x = ft, 
    part = "header", 
    i = 1, 
    j = tabulator_colnames(tab, columns = "cts", TRT01A %in% !!TRT01A_COD),
    as_chunk(trt_count[TRT01A_COD], formatter = fmt_header_n)
  )
}
ft <- autofit(ft) |> 
  align(j = 1, align = "left") |> 
  labelizor(part = "all", j = "CMDECOD", 
            labels = c(CMDECOD="", 
                       N_CM = "Number of sujects with any concomitant medication")) |> 
  hline_top(part = "header", border = fp_border_default(width=2)) |>
  set_caption("Conmed Example\nUses the 'adcm' dataset from 'random.cdisc.data'")

ft
```

### tables

```{r}
resetSession()

data("cadcm", package = "random.cdisc.data")

library(tables)
table_options(doCSS = TRUE)

subject_counts <- table(adsl$ARM)

countpercentid <- function(num, ARM) {
  n <- length(unique(num))
  sprintf("%d (%.2f%%)", 
          length(unique(num)), 
          100*n/subject_counts[ARM[1]])
}

count <- function(x) sprintf("(N=%d)", length(x))

heading <- tabular(Heading("")*1*Heading("")*count ~ 
                   Heading()*ARM, 
                   data = adsl)

body <- tabular( (Heading("Any concomitant medication")*1*Heading("")*1 + 
                  Heading()*CMCLAS*
                    Heading()*CMDECOD*DropEmpty())*
                 Heading()*countpercentid*Arguments(ARM = TRT01A)*
                   Heading()*USUBJID ~
                 Heading()*TRT01A, 
                 data = cadcm)

useGroupLabels(rbind(heading, body), indent = "&emsp;")
```

<!--chapter:end:04-05-concomitant-medications.Rmd-->

---
output: html_document
editor_options: 
  chunk_output_type: console
---
```{r include=FALSE, cache=FALSE}
library(knitr)
library(magrittr)
library(ragg)
library(random.cdisc.data)

is_doconvable <- require("doconv") && locatexec::exec_available("word")
is_webshotable <- require("webshot2")

is_truthy <- function(x) {
  if (inherits(x, "try-error"))
    return(FALSE)
  if (!is.atomic(x))
    return(TRUE)
  if (is.null(x))
    return(FALSE)
  if (length(x) == 0)
    return(FALSE)
  if (all(is.na(x)))
    return(FALSE)
  if (is.character(x) && !any(nzchar(stats::na.omit(x))))
    return(FALSE)
  if (is.logical(x) && !any(stats::na.omit(x)))
    return(FALSE)
  return(TRUE)
}

process_link_preview_options  <- function(options){
  if(!is_truthy(options$link_preview)) return("")
  if(!options$link_preview) return("")
  if(!is_truthy(options$path_to_doc)) return("")

  png_file <- gsub("\\.(pptx|docx|pdf|html)$", ".png", options$path_to_doc)
  width <- options$width
  if(is.null(width)) {
    if(!grepl("\\.pptx$", options$path_to_doc)) width <- 650
    else width <- 750
  }

  if(!file.exists(png_file) && is_doconvable && grepl("\\.docx$", options$path_to_doc)) {
    doconv::to_miniature(filename = options$path_to_doc, fileout = png_file, width = width, row = options$row)
  } else if(!file.exists(png_file) && is_doconvable && grepl("\\.pdf$", options$path_to_doc)) {
    doconv::to_miniature(filename = options$path_to_doc, fileout = png_file, width = width, row = options$row)
  } else if(!file.exists(png_file) && is_doconvable && grepl("\\.pptx$", options$path_to_doc)) {
    doconv::to_miniature(filename = options$path_to_doc, fileout = png_file, width = width, row = options$row)
  } else if (!file.exists(png_file) && is_webshotable) {
    webshot2::webshot(options$path_to_doc, vwidth = width,
      file = png_file, cliprect = "viewport")
  }

  img_code <- sprintf("![](%s)\n\n", png_file)
  lnk_code <- sprintf("::: {.office-download-link}\n\n[%s](%s)\n\n:::\n\n", options$path_to_doc, options$path_to_doc)
  return(paste0(img_code, lnk_code))
}

currentState <- function() {
  list(globals = ls(.GlobalEnv),
       search = search())
}

resetSession <- function(state = .initial_state) {
  # Clean up the search list
  for (n in setdiff(search(), state$search)) {
    detach(n, character.only = TRUE)
  }

  # Clean up the global environment by deleting everything
  # that wasn't there when `state` was constructed.
  # Objects whose name starts with "." are not deleted.

  rm(list = setdiff(ls(.GlobalEnv), state$globals),
     envir = .GlobalEnv)
}

opts_chunk$set(
  echo = TRUE,
  fig.path = "static/img/figs/",
  dev="ragg_png",
  message = FALSE,
  dpi = 150,
  comment = NA)

knit_hooks$set(link_preview = function(before, options, envir) {
  if (!before && is_truthy(options$link_preview)){
    return(process_link_preview_options(options))
  }
})

if (!exists(".initial_state")) {
  .initial_state <- currentState()
}
```

## Disposition

### rtables

```{r, comment=NA}
resetSession()

library(dplyr)
library(magrittr)
library(rtables)

data("cadsl", package = "random.cdisc.data")
adsl <- cadsl |>
  select(USUBJID, TRT01A, EOSSTT, DCSREAS)

lyt <- basic_table() |>
  split_cols_by("TRT01A") |>
  add_colcounts() |>
  split_rows_by("EOSSTT") |>
  split_rows_by("DCSREAS") |>
  summarize_row_groups()

build_table(lyt, adsl)

```
### gt

```{r}
resetSession()

library(tidyverse)
library(gt)

gt_adsl <- cadsl |> 
  dplyr::group_by(TRT01A) |> 
  dplyr::mutate(n_total = dplyr::n()) |> 
  dplyr::ungroup()

header_n <- gt_adsl |> 
  dplyr::group_by(TRT01A) |> 
  dplyr::summarize(trt = sprintf("%s  \nN=%i (100%%)", unique(TRT01A), dplyr::n()),
                   .groups = "drop") |> 
  pull(trt) |> 
  as.list()

names(header_n) <- paste0("n_", levels(gt_adsl$TRT01A))
  
gt_sum <- gt_adsl |> 
  dplyr::mutate(
    DCSREAS = dplyr::case_when(EOSSTT %in% c("COMPLETED", "ONGOING") ~ as.character(EOSSTT),
                               is.na(DTHCAUS) & EOSSTT == "DISCONTINUED" ~ as.character(DCSREAS),
                               TRUE ~ paste(DCSREAS, DTHCAUS, sep = "_"))) |> 
  dplyr::group_by(TRT01A, EOSSTT, DCSREAS) |> 
  dplyr::summarize(
    n = dplyr::n(),
    pct = dplyr::n()/min(n_total),
    .groups = "drop"
    ) |> 
  tidyr::pivot_wider(id_cols = c(EOSSTT, DCSREAS), names_from = TRT01A, values_from = c(n, pct))

dth_lbl <- gt_sum |> 
  dplyr::slice(1) |> 
  dplyr::mutate(
    across(where(is.numeric), ~NA_real_),
           EOSSTT = "DISCONTINUED",
           DCSREAS = "DEATH"
  )
  
gt_disp <- dplyr::bind_rows(gt_sum, dth_lbl) |> 
  dplyr::mutate(
    EOSSTT = factor(EOSSTT,
                    levels = c("COMPLETED", "ONGOING", "DISCONTINUED"),
                    labels = c("Completed", "Ongoing", "Discontinued")),
    DCSREAS = factor(DCSREAS,
                     levels = c("COMPLETED", "ONGOING", "ADVERSE EVENT", "DEATH" ,"DEATH_ADVERSE EVENT", "DEATH_DISEASE PROGRESSION", "DEATH_LOST TO FOLLOW UP", "DEATH_MISSING", "DEATH_Post-study reporting of death", "DEATH_SUICIDE", "DEATH_UNKNOWN", "LACK OF EFFICACY", "PHYSICIAN DECISION", "PROTOCOL VIOLATION", "WITHDRAWAL BY PARENT/GUARDIAN", "WITHDRAWAL BY SUBJECT"),
                     labels = c("Completed", "Ongoing", "Adverse Event", "Death", "Adverse Event ", "Disease Progression", "Lost to Follow Up", "Missing", "Post-Study Reporting of Death", "Suicide", "Unknown", "Lack of Efficacy", "Physician Decision", "Protocol Violation", "Withdrawal by Parent/ Guardian", "Withdrawal by Subject")) 
    ) |> 
  dplyr::arrange(EOSSTT, DCSREAS)


gt_disp |> 
  gt(rowname_col = "DCSREAS") |> 
  tab_row_group(
    label = "Discontinued",
    rows = EOSSTT == "Discontinued"
  ) |> 
  row_group_order(
    groups = c(NA, "Discontinued") 
  ) |> 
  cols_hide(EOSSTT) |> 
  fmt_integer(
    columns = starts_with("n_")
  ) |> 
  fmt_percent(
    columns = starts_with("pct_"),
    decimals = 1
  ) |> 
  sub_missing(
    rows = DCSREAS == "Death",
    missing_text = ""
  ) |> 
  cols_merge_n_pct(col_n = "n_A: Drug X", col_pct = "pct_A: Drug X") |> 
  cols_merge_n_pct(col_n = "n_B: Placebo", col_pct = "pct_B: Placebo") |> 
  cols_merge_n_pct(col_n = "n_C: Combination", col_pct = "pct_C: Combination") |> 
    sub_missing(
    rows = DCSREAS != "Death",
    missing_text = 0
  ) |> 
  cols_align(
    align = "center",
    columns = everything()
  ) |> 
  cols_align(
    align = "left",
    columns = stub()
  ) |> 
  tab_stub_indent(
    rows = 3:16,
    indent = 2
  ) |>
  tab_stub_indent(
    rows = 5:11,
    indent = 5
  ) |> 
  cols_label(
    `n_A: Drug X` = md(header_n[[1]]),
    `n_B: Placebo` = md(header_n[[2]]),
    `n_C: Combination` = md(header_n[[3]])
  ) |> 
  cols_width(
    1 ~ px(500)
  )
```


### flextable

```{r}
resetSession()

library(survival)
library(tidyverse)
library(flextable)
library(glue)

adsl <- cadsl |>
  select(USUBJID, TRT01A, EOSSTT, DCSREAS)

labels <- tools::toTitleCase(tolower(levels(adsl$DCSREAS)))
names(labels) <- levels(adsl$DCSREAS)

# data parts calculations
part_header <- adsl |> count(TRT01A, name = "n_part")

part_completed <- adsl |> filter(EOSSTT %in% "COMPLETED") |> 
  mutate(DCSREAS = "") |>
  count(TRT01A, EOSSTT, DCSREAS)

part_discontinued <- adsl |> 
  filter(EOSSTT %in% "DISCONTINUED") |> 
  count(TRT01A, EOSSTT, DCSREAS)

part_death <- cadsl |> 
  filter(EOSSTT %in% "DISCONTINUED", DCSREAS %in% "DEATH") |> 
  count(TRT01A, EOSSTT, DTHCAUS) |> 
  mutate(EOSSTT = forcats::fct_expand(EOSSTT, "Death Cause"),
         EOSSTT = "Death Cause",
         DTHCAUS = tools::toTitleCase(tolower(DTHCAUS))
         ) |> 
  rename(DCSREAS = DTHCAUS)

dat <- bind_rows(
  part_completed, 
  part_discontinued, 
  part_death) |> 
  inner_join(part_header, by = "TRT01A") |> 
  mutate(percent = n / n_part, n_part = NULL)

# Now the flextable creation with help of `tabulator()`. 

tab <- tabulator(
  dat,
  rows = c("EOSSTT", "DCSREAS"),
  columns = "TRT01A",
  `content_cell` = as_paragraph(fmt_n_percent(n, percent))
)
ft <- as_flextable(tab, spread_first_col = TRUE, 
                   columns_alignment = "right" )

TRT_COUNTS <- setNames(part_header$n_part, part_header$TRT01A)
for (TRT_COD in names(TRT_COUNTS)) {
  ft <- append_chunks(x = ft, part = "header", i = 1,
                      j = tabulator_colnames(tab, columns = "content_cell", TRT01A %in% !!TRT_COD),
                      as_chunk(TRT_COUNTS[TRT_COD], formatter = function(n) sprintf("\n(N=%.0f)", n)))
}

ft <- ft |> 
  labelizor(
    labels = c(labels, DCSREAS = "", ANY = "Number of patients", 
               COMPLETED = "Completed", DISCONTINUED = "Discontinued"), 
    j = "DCSREAS", part = "all") |> 
  align(i = ~!is.na(EOSSTT) | seq_along(EOSSTT) == 1, j = 1, align = "left") |> 
  prepend_chunks(i = ~is.na(EOSSTT), j = "DCSREAS", as_chunk("\t")) |> 
  autofit()
ft
```

### tables

```{r}
resetSession()

adsl <- cadsl

# Change the labels to title case

levels(adsl$EOSSTT)  <- tools::toTitleCase(tolower(levels(adsl$EOSSTT)))
levels(adsl$DCSREAS) <- tools::toTitleCase(tolower(levels(adsl$DCSREAS)))
levels(adsl$DTHCAUS) <- tools::toTitleCase(tolower(levels(adsl$DTHCAUS)))

library(tables)

subject_counts <- table(adsl$ARM)

countpercentid <- function(num, ARM) {
  n <- length(unique(num))
  sprintf("%d (%.2f%%)", 
          length(unique(num)), 
          100*n/subject_counts[ARM[1]])
}

count <- function(x) sprintf("(N=%d)", length(x))

heading <- tabular(Heading("")*1*Heading("")*count  ~
             Heading()*TRT01A, data = adsl)

part1 <- tabular( Heading("")*EOSSTT*DropEmpty()*
                    Heading("")*1*
                    Heading()*countpercentid*Arguments(ARM = TRT01A)*
                    Heading()*USUBJID ~
                  Heading()*TRT01A, 
                  data = subset(adsl, EOSSTT != "Discontinued"))

part2 <- tabular( Heading("")*EOSSTT*
                    Heading("")*DCSREAS*DropEmpty()*
                    Heading()*countpercentid*Arguments(ARM = TRT01A)*
                    Heading()*USUBJID ~
                  Heading()*TRT01A, 
                  data = subset(adsl, EOSSTT == "Discontinued" &
                                      DCSREAS != "Death"))

part3 <- tabular( Heading("")*DCSREAS*
                    Heading("")*DTHCAUS*DropEmpty()*
                    Heading()*countpercentid*Arguments(ARM = TRT01A)*
                    Heading()*USUBJID ~
                  Heading()*TRT01A, 
                  data = subset(adsl, EOSSTT == "Discontinued" &
                                      DCSREAS == "Death"))

useGroupLabels(rbind(heading, part1, part2, part3), 
               indent = "&emsp;")
```

<!--chapter:end:04-06-disposition.Rmd-->

```{r include=FALSE, cache=FALSE}
library(knitr)
library(magrittr)
library(ragg)
library(random.cdisc.data)

is_doconvable <- require("doconv") && locatexec::exec_available("word")
is_webshotable <- require("webshot2")

is_truthy <- function(x) {
  if (inherits(x, "try-error"))
    return(FALSE)
  if (!is.atomic(x))
    return(TRUE)
  if (is.null(x))
    return(FALSE)
  if (length(x) == 0)
    return(FALSE)
  if (all(is.na(x)))
    return(FALSE)
  if (is.character(x) && !any(nzchar(stats::na.omit(x))))
    return(FALSE)
  if (is.logical(x) && !any(stats::na.omit(x)))
    return(FALSE)
  return(TRUE)
}

process_link_preview_options  <- function(options){
  if(!is_truthy(options$link_preview)) return("")
  if(!options$link_preview) return("")
  if(!is_truthy(options$path_to_doc)) return("")

  png_file <- gsub("\\.(pptx|docx|pdf|html)$", ".png", options$path_to_doc)
  width <- options$width
  if(is.null(width)) {
    if(!grepl("\\.pptx$", options$path_to_doc)) width <- 650
    else width <- 750
  }

  if(!file.exists(png_file) && is_doconvable && grepl("\\.docx$", options$path_to_doc)) {
    doconv::to_miniature(filename = options$path_to_doc, fileout = png_file, width = width, row = options$row)
  } else if(!file.exists(png_file) && is_doconvable && grepl("\\.pdf$", options$path_to_doc)) {
    doconv::to_miniature(filename = options$path_to_doc, fileout = png_file, width = width, row = options$row)
  } else if(!file.exists(png_file) && is_doconvable && grepl("\\.pptx$", options$path_to_doc)) {
    doconv::to_miniature(filename = options$path_to_doc, fileout = png_file, width = width, row = options$row)
  } else if (!file.exists(png_file) && is_webshotable) {
    webshot2::webshot(options$path_to_doc, vwidth = width,
      file = png_file, cliprect = "viewport")
  }

  img_code <- sprintf("![](%s)\n\n", png_file)
  lnk_code <- sprintf("::: {.office-download-link}\n\n[%s](%s)\n\n:::\n\n", options$path_to_doc, options$path_to_doc)
  return(paste0(img_code, lnk_code))
}

currentState <- function() {
  list(globals = ls(.GlobalEnv),
       search = search())
}

resetSession <- function(state = .initial_state) {
  # Clean up the search list
  for (n in setdiff(search(), state$search)) {
    detach(n, character.only = TRUE)
  }

  # Clean up the global environment by deleting everything
  # that wasn't there when `state` was constructed.
  # Objects whose name starts with "." are not deleted.

  rm(list = setdiff(ls(.GlobalEnv), state$globals),
     envir = .GlobalEnv)
}

opts_chunk$set(
  echo = TRUE,
  fig.path = "static/img/figs/",
  dev="ragg_png",
  message = FALSE,
  dpi = 150,
  comment = NA)

knit_hooks$set(link_preview = function(before, options, envir) {
  if (!before && is_truthy(options$link_preview)){
    return(process_link_preview_options(options))
  }
})

if (!exists(".initial_state")) {
  .initial_state <- currentState()
}
```

`r if (knitr::is_html_output()) '
# References {-}
'`

```{r echo=FALSE}
# This comes last to clean up at the end of the
# process.
resetSession()
```

<!--chapter:end:99-references.Rmd-->

